WEBVTT

00:01:17.000 --> 00:01:21.000
That makes sense.

00:01:21.000 --> 00:01:23.000
Got it?

00:01:23.000 --> 00:01:32.000
So it's more thinking about how a technology can be used in a specific context to meet some sort of objective.

00:01:32.000 --> 00:01:36.000
Is some sort of in a structural need or objectives.

00:01:36.000 --> 00:01:56.000
So, for example, it could focus a lot on house. How people are learning right or how a teacher is teaching, or it could be a little bit more broadly, say, well, here's a more of a systemic view on this, and how this technology this platform or this company technologies support the teaching and learning process although they don't

00:01:56.000 --> 00:01:59.000
specifically focus on just content or just assessment.

00:01:59.000 --> 00:02:06.000
Or just engagement, you know, you know. So if you like, the Google suite, if that was an emerging technology for you, it's not.

00:02:06.000 --> 00:02:09.000
But if it was that could be something that you would talk about using, because you can talk about how it supports content, and it gets assessment and engagement.

00:02:09.000 --> 00:02:28.000
But it is more of a broad framework of tools rather than just a specific, you know, like I do this in the class tool, so so you can basically either zoom in, not the technology zoom, but zoom into the details of the instruction happening you know, in the light.

00:02:28.000 --> 00:02:37.000
In the live place and in person online doesn't really matter, or you could kind of more zoom out and take more of a global view of this, the instructional system.

00:02:37.000 --> 00:02:38.000
Okay.

00:02:38.000 --> 00:02:40.000
Gotcha. Okay.

00:02:40.000 --> 00:02:44.000
The challenge will be to probably do a presentation.

00:02:44.000 --> 00:02:48.000
That's only 10 min long, and that's an intentional limit. Right?

00:02:48.000 --> 00:02:51.000
I know you could probably talk about, especially if it's a broader thing you could easily do 15 or 20 min on that, and still have lots of energy around that.

00:02:51.000 --> 00:02:59.000
But we want to keep it constrained for 2 reasons. One.

00:02:59.000 --> 00:03:16.000
We, do have some limitations and that want to let everybody who has a live presentation to give to get that done and get feedback and to to highlight the most important things, because your paper is also there to support you know and expand upon those other things in general so that so 10 min is plenty for

00:03:16.000 --> 00:03:20.000
a presentation, even when it's supported by a much longer piece of work, or maybe not longer longer, but more complicated.

00:03:20.000 --> 00:03:28.000
You know, more nuanced, etc. And more details.

00:03:28.000 --> 00:03:37.000
Alright other questions, any other other project, questions.

00:03:37.000 --> 00:03:55.000
Anyone who I don't see here. Let's see Amanda, or way, or Adriene, or Danny or Linda any questions. I I can't see them in your faces, so I wanna make sure I invite you.

00:03:55.000 --> 00:03:56.000
Okay.

00:03:56.000 --> 00:04:00.000
I do have a question. So I'm looking at a sample right now. And it's yeah.

00:04:00.000 --> 00:04:01.000
You are okay.

00:04:01.000 --> 00:04:08.000
And it's taking like it's like saying, like dividing with fractions with like that technology that they're using.

00:04:08.000 --> 00:04:12.000
So like Zern is the technology they were talking about.

00:04:12.000 --> 00:04:26.000
So I'm wondering I didn't really read their whole thing, but just reading their title made me think like, so you're taking like a learning like we're like the it's like going through a content area like with a technology and like talking about.

00:04:26.000 --> 00:04:34.000
How it's like, like all the different parts of that technology and how it's like, I don't sorry.

00:04:34.000 --> 00:04:38.000
Maybe I'm not ready to ask the question yet.

00:04:38.000 --> 00:04:39.000
Okay. Okay, alright table the question until you want to bring it back.

00:04:39.000 --> 00:04:43.000
Actually, so okay, thanks.

00:04:43.000 --> 00:04:51.000
So 1 point of clarification. So I think I had read like that.

00:04:51.000 --> 00:04:56.000
It was like around, like designing a unit of instruction, using emerging technologies.

00:04:56.000 --> 00:05:07.000
But it's it sounds like what's also what what you're also saying is like, it can also be kind of like rather than use your presentation to say like this is how I'll do my unit on fractions.

00:05:07.000 --> 00:05:17.000
It's also about like thinking about how you're using a technology to meet those 3 domains that we talked about in this class and how it's like meeting a certain context rather than necessarily a specific unit.

00:05:17.000 --> 00:05:24.000
Yeah, right? And you can define scope of unit any way you want so you've got it.

00:05:24.000 --> 00:05:27.000
Right gotcha.

00:05:27.000 --> 00:05:35.000
As long as you've got an understanding what you mean by Unit.

00:05:35.000 --> 00:05:36.000
Right.

00:05:36.000 --> 00:05:43.000
I'm fine with that as long as it comes across a unit could be 10 min of instruction at the beginning of a class using some really effective technology, grab attention and to do some other things right or it could be, it could be a year-long study and here's how we're

00:05:43.000 --> 00:05:49.000
gonna use this technology to support the role of, you know, the engagement and learning across this whole year long.

00:05:49.000 --> 00:05:50.000
Kind of process.

00:05:50.000 --> 00:05:52.000
Gotcha. Okay. Great.

00:05:52.000 --> 00:05:56.000
That answered the question. I didn't know how to like work, so thank you for that.

00:05:56.000 --> 00:06:00.000
Okay. I love answering questions with just an answer without the question, hey?

00:06:00.000 --> 00:06:05.000
Yeah, without knowing the question. Yeah, I think that's pro level.

00:06:05.000 --> 00:06:06.000
You're at Europe.

00:06:06.000 --> 00:06:08.000
That's right, hey? I feel like as jeopardy, or some.

00:06:08.000 --> 00:06:15.000
Is that jeopardy? Something like that? Okay, Danny, any questions?

00:06:15.000 --> 00:06:17.000
No questions for me. Thanks.

00:06:17.000 --> 00:06:22.000
Okay. Alright. Great. Okay. Well, if you have more questions, and even if are about the project, don't hesitate to, I wouldn't interrupt the flow of the class just for that. Look.

00:06:22.000 --> 00:06:34.000
Wait to the end, but you could put it in the chat anytime cause. The Chat Transcript is part of the record, and so that will just be part that you know.

00:06:34.000 --> 00:06:36.000
I can see the chat. I don't. I don't watch it like you know.

00:06:36.000 --> 00:06:46.000
I don't gloom myself to it, but I do pay attention to it occasionally, and if I see a question I might just decide to answer, because, you know I can be distracted too.

00:06:46.000 --> 00:06:51.000
Not that that would be distracting let's take a look now not to be distracting.

00:06:51.000 --> 00:06:55.000
But let's go back. Let's go back in time to earlier today.

00:06:55.000 --> 00:06:59.000
And this is a discussion from 12. I thought I was.

00:06:59.000 --> 00:07:00.000
I thought I was adding to this, not that long ago.

00:07:00.000 --> 00:07:08.000
What I see here now. There are 45 messages that it's the system is telling me.

00:07:08.000 --> 00:07:13.000
I haven't seen. And so that means that I don't know what that means.

00:07:13.000 --> 00:07:18.000
Does that mean if I haven't seen 45, or 48 now? Oh, my gosh!

00:07:18.000 --> 00:07:19.000
It's getting higher. I think people have been posting a lot today.

00:07:19.000 --> 00:07:24.000
Whoa, look at all this? Yeah, it looks like a lot of good interaction today.

00:07:24.000 --> 00:07:39.000
So I will go back and read through all this, and add some more comments in your most likely, but this this is the kind of this is, this is the engagement pattern we get with an online discussion, especially when there's no enforcement of hey?

00:07:39.000 --> 00:07:42.000
Post post first, and like the first 3 days, and then come back and do repies, and I am very happy to see so much engagement.

00:07:42.000 --> 00:07:56.000
I really am it's just a matter of wondering, you know, if everyone gets the the problem is, it's harder to get, I think, an equitable experience that you know, because of the timing difference.

00:07:56.000 --> 00:08:03.000
So someone who needs to post earlier in the week.

00:08:03.000 --> 00:08:06.000
Guess none of this light last minute interaction. I guess that's the way it is.

00:08:06.000 --> 00:08:21.000
Anyway, we have a large enough class. This is not a large glass by any stretch of the imagination, but it's large enough so that I think everyone can still get a decent amount of interaction if they choose to be posting and I'm very happy that most of you are choosing, to

00:08:21.000 --> 00:08:24.000
be posting pretty much every week, so alright anyone want to call anything out in in the discussion, especially stuff that is new today.

00:08:24.000 --> 00:08:40.000
I haven't seen really any of this new stuff today.

00:08:40.000 --> 00:08:51.000
We're talking about adaptive assessment.

00:08:51.000 --> 00:08:52.000
Okay, well, that's.

00:08:52.000 --> 00:09:06.000
Sorry I was gonna say not. Not in this discussion on adaptive assessment necessarily, but I just wanted to share with people that I heard a recent Npr.

00:09:06.000 --> 00:09:12.000
Interview with I don't think it was Npr, but it was like a Kqg.

00:09:12.000 --> 00:09:16.000
Like interview with the George Henson, who was Jeffrey?

00:09:16.000 --> 00:09:18.000
Jeffrey Hinton. I listened to that.

00:09:18.000 --> 00:09:23.000
Thank you. Yes, thank you. I'm like George or Jeffrey.

00:09:23.000 --> 00:09:28.000
He's like he's noticed like the godfather of AI, who worked for Google for very long, developing like the technology behind generative AI, and he just stepped down.

00:09:28.000 --> 00:09:36.000
I think, like a couple days ago from Google, because he was.

00:09:36.000 --> 00:09:46.000
He wanted to warren the world about what he perceives to be the dangers of AI.

00:09:46.000 --> 00:09:47.000
And it was really fascinating to kind of listen to that.

00:09:47.000 --> 00:10:04.000
That interview. But if anybody wants to hear it, it was also in a like a New York Times article, and I posted it on the Reflections for learning like our, you know, our formative assessment Reflections for this class.

00:10:04.000 --> 00:10:07.000
Anyway, it was just very fascinating.

00:10:07.000 --> 00:10:28.000
And then in the same breath, there was Dr. Vivek Murthy, who talked about like the growing epidemic of loneliness in our society, that I feels totally facilitated by a lot of social media, and so anyway, I connected the 2 in

00:10:28.000 --> 00:10:35.000
in the reflections on learning. If anybody wants to kinda take a look at those 2 things, that's it.

00:10:35.000 --> 00:10:39.000
Yeah, so we have this, we almost have this picture storm here, don't we?

00:10:39.000 --> 00:10:46.000
We've had. More like a year or 2 ago, you know the threat of social media, and how it was being designed to basically suck the life out of people through completely keeping them attracted to their devices.

00:10:46.000 --> 00:10:55.000
That's my paraphrasing, of course. But you know, the movie was social network, right?

00:10:55.000 --> 00:10:58.000
That kind of thing that's very real that didn't go away.

00:10:58.000 --> 00:10:59.000
Right.

00:10:59.000 --> 00:11:00.000
That's bad as it ever was. Probably. Now we have AI.

00:11:00.000 --> 00:11:09.000
We have the loneliness, epidemic I think there's, I think there's a story I mean, there's obviously story and stories there.

00:11:09.000 --> 00:11:11.000
It'd be it's actually not so.

00:11:11.000 --> 00:11:24.000
I think it's a reflective opportunity for everybody, you know, for yourself, for your the people who are around you, your family unit, or whatever you might want, how you want to find that as well as if you're a teacher in a classroom your students in your classroom, I mean, it's I think it's I think it's a actually

00:11:24.000 --> 00:11:26.000
Yeah.

00:11:26.000 --> 00:11:35.000
it's a perfect setup, essentially, for tonight's topic around assistive technology and specifically personal learning environments, right or personal learning networks.

00:11:35.000 --> 00:11:38.000
However, you want to use that term, because it's talking a lot about it.

00:11:38.000 --> 00:11:45.000
That's exactly what we're talking about here. What are the technologies that people are using to support their learning?

00:11:45.000 --> 00:11:56.000
And a lot of these are social technologies, or could be, and a lot of them could be, you know, could be AI powered technologies, or even the AI engines themselves.

00:11:56.000 --> 00:11:57.000
And so I think this idea of a loneliness epidemic.

00:11:57.000 --> 00:12:02.000
I haven't thought about that in terms of a personal learning environment.

00:12:02.000 --> 00:12:10.000
But you know that's an interesting idea. If our learning environment becomes more and more technology mediated, does it?

00:12:10.000 --> 00:12:14.000
Haven't have an impact on our social connect. Our real life.

00:12:14.000 --> 00:12:17.000
Excuse me, social connections.

00:12:17.000 --> 00:12:30.000
Well, I I I just bring that up because I recently also was charged with like creating a survey for our faculty post pandemic.

00:12:30.000 --> 00:12:50.000
I'm getting paid for it. But like so, I'm working as part of a team to create like a post pandemic survey for our faculty in terms of like kind of trying to influence policy about whether or not we have a remote a remote teaching policy and how

00:12:50.000 --> 00:12:51.000
Hmm!

00:12:51.000 --> 00:12:52.000
we can enforce that or facilitate that, or institute that.

00:12:52.000 --> 00:13:09.000
And one very interesting finding I've found from that survey is that, on the one hand, and I can relate to this like faculty are really grateful for the flexibility of being able to teach more online classes and more and in different modalities that were never touched before the

00:13:09.000 --> 00:13:13.000
pandemic, that allow for more flexibility in our lives.

00:13:13.000 --> 00:13:15.000
So, on the one hand, this piece of like getting more work-life balance is being met by that.

00:13:15.000 --> 00:13:30.000
But, on the other hand, faculty are also experiencing more dessatisfaction with teaching, and I think a lot of that comes with the fact that it just doesn't feel the same.

00:13:30.000 --> 00:13:31.000
Yeah.

00:13:31.000 --> 00:13:33.000
It doesn't feel the same when you're in a classroom versus when you're on line.

00:13:33.000 --> 00:13:44.000
And the same sort of like social rewards. Right?

00:13:44.000 --> 00:13:45.000
Yeah.

00:13:45.000 --> 00:13:46.000
The the emotional aspect of teaching is not the same.

00:13:46.000 --> 00:13:51.000
When you're not in front of people in person.

00:13:51.000 --> 00:13:56.000
And and so I we kept seeing that, like people were rating.

00:13:56.000 --> 00:14:05.000
You know aspects of teaching post pandemic really high on, like the levels of being able to have more control over the schedule and more flexibility.

00:14:05.000 --> 00:14:06.000
But really low on the levels of having it feel rewarding.

00:14:06.000 --> 00:14:13.000
So I I think that there's something there that we have to pay attention to.

00:14:13.000 --> 00:14:29.000
Certainly, I mean, if you think reluct on your own experience when we when we went completely online in the pandemic, most of us to almost completely synchronize with maybe some asynchronous, especially if we've been doing it before.

00:14:29.000 --> 00:14:35.000
Very different experience. I remember my first classroom experience during the pandemic about a year ago.

00:14:35.000 --> 00:14:46.000
Maybe I was invited to speak to a class, so like a guest class, a class that was visiting the campus about flexible of, you know, hybrid, high flex, essentially.

00:14:46.000 --> 00:14:53.000
And these were these were international students, primarily, and they wanted to hear about this thing, that some American schools were doing.

00:14:53.000 --> 00:14:56.000
And so they were. They did not have a choice. They had to be there in person.

00:14:56.000 --> 00:14:59.000
There was like 20 people in the room, all in masks.

00:14:59.000 --> 00:15:00.000
That was there I don't remember if I had to talk in a mask or not.

00:15:00.000 --> 00:15:10.000
I don't. I think I might have, but I did this presentation for about an hour, and I got some, you know, some that was so energizing for me.

00:15:10.000 --> 00:15:11.000
I couldn't believe it. I could not believe the emotional reward I got for being there and then coming back to classes.

00:15:11.000 --> 00:15:20.000
And it's like, all online. I'm sitting in my home office.

00:15:20.000 --> 00:15:23.000
It's a it's like, Wow, this, this is just so different.

00:15:23.000 --> 00:15:30.000
And then in a class, this semester one of my classes, basically, we had too few people participating online synchronously.

00:15:30.000 --> 00:15:34.000
So it made sense to move it all asynchronously.

00:15:34.000 --> 00:15:44.000
A whole nother's different set of set of emotional rewards as as to user terminology, and I don't don't like that.

00:15:44.000 --> 00:15:45.000
I I appreciate students who need asynchronous.

00:15:45.000 --> 00:15:46.000
And I appreciate students who need online. But I I would rather be in the classroom.

00:15:46.000 --> 00:15:53.000
So my challenge as a teacher is to still be able to teach online synchronously with energy.

00:15:53.000 --> 00:16:05.000
And online asynchronously, with energy and excitement, so that the students don't feel like the teacher doesn't want to be here even when the teacher may not want to be here.

00:16:05.000 --> 00:16:08.000
They might want to do this in a different way, completely right.

00:16:08.000 --> 00:16:09.000
So that's that's a real challenge.

00:16:09.000 --> 00:16:18.000
And until until you experience that I don't think you can get that, you don't understand. You see it academically.

00:16:18.000 --> 00:16:20.000
These are right about it. Talk about it, you know. People will.

00:16:20.000 --> 00:16:27.000
You know, we'll pay you money to talk about it, as a matter of fact, and yet, until it's lived through, they really don't know.

00:16:27.000 --> 00:16:35.000
I can't, though, Dalton, I missed your hand earlier. Do you still wanna say something?

00:16:35.000 --> 00:16:36.000
And then Adam.

00:16:36.000 --> 00:16:50.000
Yeah, sure. AI, I noticed that there's more and more calls from experts and leaders in this field for for regulation I'm wondering in your experience in instructional technology world, you know, during your career.

00:16:50.000 --> 00:17:03.000
Have you noticed any regulations being passed that limit? You? I don't know. There's a lot of regulations that have been passed that will create equal right and equitable access to technology in the classroom.

00:17:03.000 --> 00:17:07.000
But has there been any anything that sort of like limits it, or anything that was like?

00:17:07.000 --> 00:17:08.000
Hmm!

00:17:08.000 --> 00:17:12.000
Oh, this is dangerous. We recognize this dangerous. So let's limit it.

00:17:12.000 --> 00:17:16.000
I don't know so at least not on a system level.

00:17:16.000 --> 00:17:19.000
There may be schools or departments that have said, Hey, look!

00:17:19.000 --> 00:17:20.000
We are not teaching like our math classes. Maybe they would make.

00:17:20.000 --> 00:17:30.000
They might say something about to certain style of teaching within their own little program, but I haven't seen anything more broadly than that.

00:17:30.000 --> 00:17:36.000
Even when I was in high school. I think the school was very supportive of technology, because it was relatively early in a days.

00:17:36.000 --> 00:17:40.000
And everybody thought, Oh, using more technology, that's gotta be better right?

00:17:40.000 --> 00:17:44.000
Maybe not.

00:17:44.000 --> 00:17:48.000
There are. Yeah. Well, so the yeah, maybe in this direction, our science departments have told their faculty.

00:17:48.000 --> 00:18:03.000
They do not want their faculty using online labs they want hands on lamps, and they'll require all the students to be here for those kind of lab experiences because they do not believe that students will get the same laboratory experience. And they're right.

00:18:03.000 --> 00:18:08.000
They can't get the same experience question, is it? Do they get a good enough experience online? Right?

00:18:08.000 --> 00:18:10.000
That's the question they have to wrestle with.

00:18:10.000 --> 00:18:11.000
And right now they're saying actually, no, we're not happy with that.

00:18:11.000 --> 00:18:12.000
And so they're gonna limit access to the lab environment.

00:18:12.000 --> 00:18:27.000
To only those people who can be here, but in their program they still have as many students as they can possibly serve so it's not a there's a supply challenge as well as an there's like an over demand, I think, but there's a supply.

00:18:27.000 --> 00:18:38.000
Limitation, that that isn't really seen on campus at the faculty level, because they still they have plenty of students in their classes.

00:18:38.000 --> 00:18:43.000
So from the faculty's perspective. Yeah, not a problem.

00:18:43.000 --> 00:18:46.000
Addam, you were gonna say something, I think.

00:18:46.000 --> 00:18:58.000
Yeah, I just thought it was interesting that like Marie, when you brought up social media and AI than I as you saw in the chat, I immediately chat social media and remote work, because I'm a fully remote employee.

00:18:58.000 --> 00:19:12.000
I worked for my company, for what? Before the pandemic, 5 years before we before the pandemic, and it was like, yes, there were times where I didn't want to be in the office, or it was really inconvenient, but like I definitely got a ton of social reward, and community.

00:19:12.000 --> 00:19:23.000
From my colleagues, and then, like so many companies in the effort to try to get employees back to the office.

00:19:23.000 --> 00:19:24.000
Every time our CEO, or leadership tried to do it.

00:19:24.000 --> 00:19:35.000
It was just met with such a revolt we're legitimate reasons that people have.

00:19:35.000 --> 00:19:39.000
It resulted in like us closing even some of our offices.

00:19:39.000 --> 00:19:45.000
And, like, you know, even we have a couple of offices that still exist in those anytime.

00:19:45.000 --> 00:19:46.000
There's any mention of like. Oh, there's benefits to being in person.

00:19:46.000 --> 00:19:53.000
It. There's the there's the revolt again.

00:19:53.000 --> 00:19:59.000
So it's just like it's I don't know where we're going to to go, and maybe revolt's too strong of a word.

00:19:59.000 --> 00:20:01.000
But I mean and there are legitimate reasons why not?

00:20:01.000 --> 00:20:02.000
Everyone can always come into the office, and it does alienate certain people.

00:20:02.000 --> 00:20:08.000
And it's just it's such a. It's such a difficult balance.

00:20:08.000 --> 00:20:15.000
And I'm Dr. B. It sounds like it's maybe even happening at like the institutional level at Sf stage.

00:20:15.000 --> 00:20:22.000
Yeah, oh, definitely, our senior administration has been telling faculty undergraduate teaching faculty or the departments at teach.

00:20:22.000 --> 00:20:27.000
A lot of undergraduate students, 75% of your sections have to be in person only right?

00:20:27.000 --> 00:20:28.000
Not hybrid, not on, not a mix online, no flexibility. They have to be here.

00:20:28.000 --> 00:20:36.000
Why? Because we want students here on campus. And we want faculty here on campus to graduate programs.

00:20:36.000 --> 00:20:39.000
They told us pretty much. They understand our students a little bit better, saying, because if we had to do that we would have, we would lose at least half our students.

00:20:39.000 --> 00:20:48.000
If not more so. They they're not leaving us alone, and yet we there's this conversation going on.

00:20:48.000 --> 00:20:58.000
Campuses are things that you can. We can use the to bring in that we kind of restore and maybe enhance that sense of community without it only being coordin.

00:20:58.000 --> 00:21:03.000
Only class-pass participation, driven. And so we have. You know, we have lots of dorms on campuses.

00:21:03.000 --> 00:21:10.000
So that's one thing, the living environment on campus, including the sports, environment and other kinds of things to do.

00:21:10.000 --> 00:21:15.000
The university knows it's in a place where it's kind of like a like an activity shadow.

00:21:15.000 --> 00:21:19.000
There, there's not a lot going on around the Mega on the campus unless it's right on the campus.

00:21:19.000 --> 00:21:23.000
But that's not a lot, even though we don't have big sports things that I know.

00:21:23.000 --> 00:21:27.000
We have some scores, but not like big sports. You'd come here for. So you have.

00:21:27.000 --> 00:21:39.000
It's a everything's a mutiny rid away or a bart right away, and you know that's not the same as a lot of other campuses where the campus actually is the center of life, you know, maybe for a town.

00:21:39.000 --> 00:21:47.000
Yeah, I'm thinking of, like the midwestern, you know the like universal versus constant in Madison.

00:21:47.000 --> 00:21:51.000
I went to University or Illinois, or Indiana University in Bloomington.

00:21:51.000 --> 00:21:56.000
That campus was was the center of life, you know, really, for the town, at least from our perspective.

00:21:56.000 --> 00:21:59.000
So yeah, it's a big, there is a big challenge.

00:21:59.000 --> 00:22:03.000
And I think our social environment on campus has gotten a lot better from year to year.

00:22:03.000 --> 00:22:13.000
This compared to what year last year, year, especially for the undergraduates, to some extent to a lot of the grad programs, especially when they have a lot of hands on things not so much.

00:22:13.000 --> 00:22:27.000
And I think we have to learn how to do that but I'm gonna try to focus a little bit more on that and make more opportunities available in person, if not on campus, at least in person, somewhere, because it is a different kind of building on that network when you're talking to people around the table or you

00:22:27.000 --> 00:22:30.000
know, you know, sharing a beverage, or whatever it might be.

00:22:30.000 --> 00:22:38.000
So we did our. We did our one little VR meet up this last semester gonna do that again in some other class, probably next year or next semester.

00:22:38.000 --> 00:22:45.000
And then we have an opportunity for a meetup with some ids in May maybe not the most convenient time.

00:22:45.000 --> 00:22:48.000
But May was it May nineteenth, I think, downtown.

00:22:48.000 --> 00:22:54.000
So you know another opportunity you try to do more things like that.

00:22:54.000 --> 00:22:56.000
Go ahead! Marie!

00:22:56.000 --> 00:23:15.000
Yeah, I just wanted to, you know, to elevate what it's a way, what what Linda was saying is that a lot of companies wanna bring back in place for like communication and small talk, and just that sort of team building that happens in person that community building.

00:23:15.000 --> 00:23:32.000
And when I was listening to like the Jeffrey Hinton's like dystopian view of the future in which we are controlled by AI, which is smarter than humans, is super scary on one hand, and then I just cut it go me thinking about

00:23:32.000 --> 00:23:35.000
like, what can humans do, and what kind of human intelligence do we have?

00:23:35.000 --> 00:23:44.000
That's very unique to to being human, that AI couldn't really replicate. Very well.

00:23:44.000 --> 00:24:02.000
And what I realized that we have, that AI doesn't have at least not yet is our ability to empathize in our ability to build community and social networks, and as much as as you know, the sort of like social media has tried to build social networks.

00:24:02.000 --> 00:24:13.000
It's just really not the same right like the social net social networks that you get on on social media don't feel the same right.

00:24:13.000 --> 00:24:18.000
Then the ones that you build in person over your lifespan.

00:24:18.000 --> 00:24:21.000
They're not used the same way.

00:24:21.000 --> 00:24:45.000
Really, you don't. They don't provide the same kind of benefit emotionally to people.

00:24:45.000 --> 00:24:46.000
Bye!

00:24:46.000 --> 00:24:48.000
And so it just made me realize, like if we, if we give in to AI, you know, if we continue to isolate ourselves from other people, then we don't really work to kind of build those empathy muscles that are so important to human intelligence that make us human and and then Linda, I

00:24:48.000 --> 00:24:50.000
see you said like, you know, the same office talks, play a critical role in promotion.

00:24:50.000 --> 00:24:55.000
You're right. Because, like, that's actually part of our social network, right?

00:24:55.000 --> 00:24:56.000
Like that's that's part of how we build this as people.

00:24:56.000 --> 00:24:58.000
Social capital that we then use to kind of parlay into different opportunities. Right?

00:24:58.000 --> 00:25:13.000
Like getting a promotion, or Hey, you know somebody who also, who baby sits.

00:25:13.000 --> 00:25:14.000
Kids that are this age cooled. Can you see if they could babysit?

00:25:14.000 --> 00:25:37.000
My, you know, like these like really spontaneous things that happen in in-person interaction that don't happen in the same way, in social interaction, online and social networks online is like very shallow kind of very performative and very in the moment, and it disappears right kind

00:25:37.000 --> 00:25:44.000
of in some ways, but in person it just. It's it's very like as the as a young kids say these days.

00:25:44.000 --> 00:25:45.000
It hits different. Right? It's just. It's very, you know.

00:25:45.000 --> 00:25:54.000
It just it. Kind of leaves more of a lacking impression on you in a lot of ways, right?

00:25:54.000 --> 00:26:02.000
Like you could have one interaction with somebody, and depending on how that interaction makes you feel like you could remember it years down the line versus like something that happens on social media.

00:26:02.000 --> 00:26:11.000
It could upset you. But it's not gonna stay with you, you know.

00:26:11.000 --> 00:26:12.000
Yeah.

00:26:12.000 --> 00:26:13.000
It's not gonna be kind of a lasting mark on you. Hopefully, right?

00:26:13.000 --> 00:26:14.000
I don't know. Maybe I'm wrong. You don't have to agree with me.

00:26:14.000 --> 00:26:25.000
That's just sort of my musings. But like that's what I was sort of thinking about earlier today is like what makes us uniquely human, that we can't be supplanted because I'm I'm legitimately afraid of.

00:26:25.000 --> 00:26:33.000
Honestly robots taking over the world, but you know, maybe that's just me and my crazy brain.

00:26:33.000 --> 00:26:38.000
But like after I was like, Oh, my God! That is really a very, very sounded fear on behalf of Jeffrey and I think that I'm also afraid of that.

00:26:38.000 --> 00:26:44.000
But anyway.

00:26:44.000 --> 00:26:45.000
Interesting that one last on this red rabbit trail that we'll kind of pull back to the mainline for tonight.

00:26:45.000 --> 00:26:55.000
I've been rereading or reading some of them for the first time.

00:26:55.000 --> 00:27:00.000
Isaac Asimov's signs, fiction, short stories, and most of the ones I'm reading now are written in the fifties, and a lot of them are are talking about one of them in particular.

00:27:00.000 --> 00:27:08.000
There's a whole strand of stories about this. This computer.

00:27:08.000 --> 00:27:15.000
I figure what they call it Max. You know something something anyway, it's a computer that essentially is this huge AI becomes a Suji, and from his earlier stories to the later stories it basically starts to be this.

00:27:15.000 --> 00:27:20.000
And the one thing that has all the answers.

00:27:20.000 --> 00:27:32.000
And so people start, stop, they stop learning, cause they just have to ask the ask the computer, you know, and they get the answer just like that.

00:27:32.000 --> 00:27:33.000
And until they ask the computer, a question, the computer can't answer.

00:27:33.000 --> 00:27:40.000
Then the kind of like the whole world falls apart. But you didn't write about that part, but it's interesting that you know a lot of these ideas have been around for a long time.

00:27:40.000 --> 00:27:55.000
We're starting to see the more and more of them coming to fruition, and at least in some form it'll never show up exactly the way we think it will.

00:27:55.000 --> 00:27:57.000
It'll be different. I don't know. I you know, Scary.

00:27:57.000 --> 00:28:02.000
I'm not sure. Maybe probably some elements, but I don't think we really understand it until once again.

00:28:02.000 --> 00:28:18.000
Sometimes we have to kind of live through it. I'm hoping that people are designing for good and not just for gain, and unfortunately, a lot of a lot of the way our system works, that there's a lot of lot of reward for being in it for gain not just for

00:28:18.000 --> 00:28:25.000
good. So with that, we are talking about accessible technology and personal learning networks.

00:28:25.000 --> 00:28:29.000
Let's start by looking at assistive technology. And I want to.

00:28:29.000 --> 00:28:30.000
Well, let's talk a little bit about. I give you one reading to do here a simple little thing.

00:28:30.000 --> 00:28:39.000
What was it? So? This was no. Where was it?

00:28:39.000 --> 00:28:45.000
Hmm! Not that one here, just one right simple little blog!

00:28:45.000 --> 00:28:46.000
The future is here assistive technology for learning disabilities.

00:28:46.000 --> 00:28:57.000
Most of the when you look for people talking about assistive technologies, especially online these days, most of them are talking about technologies to support learning disabilities.

00:28:57.000 --> 00:29:01.000
And they're defining learning disabilities. Very broad.

00:29:01.000 --> 00:29:06.000
You know, including including physical, you know, ability, differences like I can't hear very well, or I can't see very well, or I don't have good motor control.

00:29:06.000 --> 00:29:15.000
And that impacts my ability to learn. Sort of it really impacts my ability to learn insertin ways doesn't mean I can't. It doesn't mean I have trouble learning.

00:29:15.000 --> 00:29:16.000
If I can get the information, it's maybe I can't see it visually.

00:29:16.000 --> 00:29:20.000
I can't see it. So the visual channels not working as well.

00:29:20.000 --> 00:29:26.000
I can't see it. So the visual channels not working as well, or I can't hear it.

00:29:26.000 --> 00:29:32.000
So the audio channel, you know, need some supplement or support, or I have to be able to get something differently.

00:29:32.000 --> 00:29:40.000
And so sometimes the assistive technologies are there to really kind of give us access through a different sensory path, and then would normally be provided alright.

00:29:40.000 --> 00:29:42.000
So when we caption videos, one of the reasons we do those is for people who may not be able to hear us or understand our language.

00:29:42.000 --> 00:29:56.000
And then we can give them captions which put it into a written language that they can see, and maybe even can be translated into a language they're more used to learning.

00:29:56.000 --> 00:30:14.000
They still have to be able to process the language mentally in order to, you know, you know, get the get kind of get the message right, develop the understanding from what the intent is, and then there are other technologies, you could even consider, someone's assistive, technology to get them to the learning space if it's

00:30:14.000 --> 00:30:22.000
only in the classroom, you know, like in, you know, a motorized vehicle, or, you know, with a prosthetics to help them move themselves.

00:30:22.000 --> 00:30:23.000
That could be assistive technology. It depend on how broadly you define that.

00:30:23.000 --> 00:30:28.000
That's not normally part of the system technology definition for campus.

00:30:28.000 --> 00:30:32.000
But in general the big picture is, yeah, it's assistive technology.

00:30:32.000 --> 00:30:47.000
There's a there's a lot going on in that area, and has been for quite a while as far as helping people, you know, kind of, you know, get support where they needed, especially when they've been injured in some particular way, and there are a lot of other technologies that are focused

00:30:47.000 --> 00:30:55.000
on helping people, where're learned where, where the operate in the brain, right is is not working the way we would expect it to. For example.

00:30:55.000 --> 00:31:00.000
So someone who can't see letters in the order that someone presents them in dyslexia you know, there are some technologies that are are helping people who have dyslexia.

00:31:00.000 --> 00:31:10.000
Or there's a discrefia right where you have that problem, not with letters, but with numbers. Right?

00:31:10.000 --> 00:31:29.000
So numbers become a problem, or well, you know pretty much. You can name a lot of different things or Adhd add. You know, there are different tools that can be used to support people with those kinds of differences in the way their brain is functioning, especially when they're trying to learn some things.

00:31:29.000 --> 00:31:32.000
I'm sure many of you have some experience with this.

00:31:32.000 --> 00:31:37.000
What did you? What do you wanna say about it?

00:31:37.000 --> 00:31:43.000
Just kind of in general. At this point.

00:31:43.000 --> 00:31:48.000
Right. Here's a here's a kind of a list.

00:31:48.000 --> 00:31:49.000
Yeah, there's a more formal list. So I have another one over here.

00:31:49.000 --> 00:31:55.000
This one?

00:31:55.000 --> 00:31:59.000
This one's more like from a academic kind of thing. Mari.

00:31:59.000 --> 00:32:01.000
I'm sorry, I know I talk a lot.

00:32:01.000 --> 00:32:04.000
I'm sorry for anybody who's tired of me.

00:32:04.000 --> 00:32:14.000
I just wanted to say I'm really well versed in this, because I have a daughter who is autistic, and she's also dyslexic and discgraphic.

00:32:14.000 --> 00:32:34.000
And so it's been a lifelong challenge, you know, for her to to have the accommodations in place that she needs to be successful in a tradition classroom, and I've really had to learn a lot about so many things so many accommodations and assistive

00:32:34.000 --> 00:32:47.000
technologies. And I. So what we use with her are a range of different different tech to help her kind of complete her homework.

00:32:47.000 --> 00:32:58.000
You know things that range from like just simple, like speech to text kind of stuff with Google Docs, for example, she had learning la, which has been really great.

00:32:58.000 --> 00:33:11.000
So learning ally is an app that actually the State of California sorry the State of California provides people with dyslexia, and I think it might be a federal program.

00:33:11.000 --> 00:33:17.000
But, like anyone who has a documented disability, that's a language language based learning.

00:33:17.000 --> 00:33:32.000
Disability has access to learning, ally, and learning. Ally has, like millions and millions of titles of books that will read to you while you can see the print.

00:33:32.000 --> 00:33:39.000
And so that's super helpful for her. She has an account that's free, so it'll give you.

00:33:39.000 --> 00:33:46.000
Yes, learning allies is amazing. And then, you know, we also just do kind of audiobooks.

00:33:46.000 --> 00:33:59.000
And one thing I've noticed with her, her brain is that I don't do a good job of retaining information audio, but like she does so like she can hear one.

00:33:59.000 --> 00:34:07.000
She can hear her story and recount details about the story.

00:34:07.000 --> 00:34:25.000
Years later, you know for me, I'm very much like I have to read it like I very much need to read things to retain that kind of information is how my brain is wired, but hers is wired that she can hear it, and that that'll help her retain things

00:34:25.000 --> 00:34:31.000
and one thing that I also learned about, like about assistive technology, is it?

00:34:31.000 --> 00:34:54.000
It doesn't have to be super high tech, right? It can be really low tech, like assistive technology is just referred to any kind of tool that helps people learn that is, that is not part of sort of the normal range of like that's not part of the typical set of learning tools so

00:34:54.000 --> 00:34:55.000
like, even something like we use like a little highlighter strip.

00:34:55.000 --> 00:35:02.000
So it's like a roller with like a a highlighter in the middle, that probably all the K.

00:35:02.000 --> 00:35:13.000
12 teachers are familiar with, but, like, you know, we use that to kinda help her cause, like people who are dyslexic sometimes are.

00:35:13.000 --> 00:35:17.000
They have visual sensory overload. And this is definitely the case for my daughter.

00:35:17.000 --> 00:35:18.000
So it's hard for her to just single out one sentence in a paragraph.

00:35:18.000 --> 00:35:33.000
And so it's really helpful for her to be able to block out whatever sentence she's not reading, and so they have these rulers that have like just a little highlighter strip in the middle.

00:35:33.000 --> 00:35:34.000
That's transparent, and everything else is opaque.

00:35:34.000 --> 00:35:49.000
And so you use that, and you just kind of move it along down the page as you're as you're reading in a helps to block out all of the other visual information that isn't necessary for that.

00:35:49.000 --> 00:35:53.000
So it ranges from low tech to high tech, and and so I don't know.

00:35:53.000 --> 00:35:58.000
I've done a lot of trainings with like parents helping parents, so I could.

00:35:58.000 --> 00:36:01.000
I could talk probably more than I should about this, but.

00:36:01.000 --> 00:36:05.000
Well, and you have to be. I mean, you're in a role you have to be.

00:36:05.000 --> 00:36:16.000
You have to do that. You have to be an advocate, you know, because you you can't really trust that the teacher in the school or the school system is gonna be that advocate hopefully, they will be.

00:36:16.000 --> 00:36:20.000
But you're no. The student needs a voice, and someone needs to have that for them.

00:36:20.000 --> 00:36:27.000
So the fact that a parent, or parent, or guardian, or someone else who who can help advocate for them is really important.

00:36:27.000 --> 00:36:42.000
I think, to success, and you're right. It doesn't have to be tech technology. That's complicated. And quite honestly, there are probably a bunch of technologies out there that you know when they first introduced may have been introduced as aive technologies.

00:36:42.000 --> 00:36:46.000
Or could have been called assistive technology, that we wouldn't call assistive technologies.

00:36:46.000 --> 00:36:49.000
Today, I think of my use of grammarly.

00:36:49.000 --> 00:36:50.000
It. It's a perfect example of an aive technology, because my fingers don't type.

00:36:50.000 --> 00:36:57.000
I know how to spell, but my fingers don't know how to spell.

00:36:57.000 --> 00:37:09.000
So when I'm using the keyboard, so when I'm using the keyboard, I have a lot of misspelled words, and grammarly is now fixing probably 95% of them without me even noticing them, because I'm I'm not looking at that I'm looking at my

00:37:09.000 --> 00:37:15.000
keyboard, or something like I'm not supposed to but that's that, you know, and we're finding more and more that translate.

00:37:15.000 --> 00:37:22.000
Translators, automatic translations, you know, can be considered assessive technology, especially if you're working in a language.

00:37:22.000 --> 00:37:27.000
It's not your native language, or one that you don't have fluent speech in other examples.

00:37:27.000 --> 00:37:30.000
Can anyone think of other examples? Technologies you use that are assisting you?

00:37:30.000 --> 00:37:41.000
In ways that are maybe kind of. Maybe one time would have been out of the normal but now are sort of becoming a normal part of the way we live.

00:37:41.000 --> 00:37:48.000
Our lives instructionally work wise socially, it doesn't really matter.

00:37:48.000 --> 00:37:53.000
Reading fonts, Linda.

00:37:53.000 --> 00:38:01.000
Oops. Sorry? Yeah. So I recently the Adhd reading forms.

00:38:01.000 --> 00:38:02.000
Hmm!

00:38:02.000 --> 00:38:19.000
I don't know if they have a generators for it, so I'm not diagnosed with Adhd, but I have really hard time sitting and just reading a paragraph even sentence oftentimes, especially when it's just like a book, or academic products, but like

00:38:19.000 --> 00:38:34.000
I saw an example online somewhere that they applied the Adhd reading form to it, and and I was able to kind of read the full pair of without really my attention going somewhere else.

00:38:34.000 --> 00:38:35.000
Hmm!

00:38:35.000 --> 00:38:44.000
So I thought that was pretty interesting. But I don't know if there's a generators for stuff like that. Yeah.

00:38:44.000 --> 00:38:45.000
Yeah, interesting. I I I didn't know.

00:38:45.000 --> 00:38:58.000
That makes a lot of sense that the way they shape the fonts, you know, certainly influences the way you are reading it.

00:38:58.000 --> 00:39:07.000
Yeah, well, so you know, a designer who's working in with text, especially text online.

00:39:07.000 --> 00:39:23.000
And certainly, if you know, you haven't a population, you know part of your audience does have a particular characteristics where font really matters more than others, you they should know more about that, and there are probably some good guidelines to follow I wonder if the technical writing people know

00:39:23.000 --> 00:39:27.000
more about that.

00:39:27.000 --> 00:39:35.000
So essentially, I can drop. I can share, like real quick, what essentially is, it's not what it does is in the article.

00:39:35.000 --> 00:39:44.000
They have an example of it. So it's it bolds the first couple characters of a word.

00:39:44.000 --> 00:39:52.000
So it's I don't know what the signs behind it is, but like it's just oh, it's in the chat I just dropped, and it just allows me to focus it.

00:39:52.000 --> 00:39:55.000
Yeah, I'm thinking, I think I'm.

00:39:55.000 --> 00:40:00.000
If you go. Oh, you can ext that out. That's I think that's just an add.

00:40:00.000 --> 00:40:01.000
Oh, I was trying to figure that one out. Yeah.

00:40:01.000 --> 00:40:17.000
If you go a little under, keep scrolling, keep going, and then.

00:40:17.000 --> 00:40:20.000
Right there. It looks like that.

00:40:20.000 --> 00:40:21.000
Uhhuh.

00:40:21.000 --> 00:40:31.000
So that was, it's really helpful for me, like for me to stay focused on. I'm like reading the holes, sentence or paragraphs.

00:40:31.000 --> 00:40:44.000
So bold in the folding. The first, the most probably the first important letters of each word makes a difference.

00:40:44.000 --> 00:40:45.000
Huh!

00:40:45.000 --> 00:40:46.000
So I know this was pretty interesting. But again, I'm not really diagnosed with it.

00:40:46.000 --> 00:40:54.000
We'll see. But if somebody hasn't actually diagnosed, and if they can transition, apparently it's a lot of people are benefiting from it.

00:40:54.000 --> 00:40:59.000
From the reaction from online.

00:40:59.000 --> 00:41:07.000
Amazing that would happen. Huh? We put a technology in place to help people with a particular challenge.

00:41:07.000 --> 00:41:16.000
And it turns out to help even people who either didn't know they had the challenge or don't have that challenge, but find that still makes their life easier.

00:41:16.000 --> 00:41:20.000
That ever happened with another assistant technology, I mean, come on, this is like this is the story of assistive technology.

00:41:20.000 --> 00:41:26.000
Really morning?

00:41:26.000 --> 00:41:27.000
Yeah, I think I think, cause I we've been talking to you. Dr.

00:41:27.000 --> 00:41:44.000
Bee about our project, but Adam and I are doing our final project together, and that's actually one of the major themes of our paper is that so we're focusing on on assistive technology called auto.

00:41:44.000 --> 00:41:46.000
That!

00:41:46.000 --> 00:41:48.000
You wanna jump into that now, or just we can start.

00:41:48.000 --> 00:41:50.000
Oh, I thought you were queuing us!

00:41:50.000 --> 00:41:51.000
Well, it turns out I am.

00:41:51.000 --> 00:41:58.000
We don't have to I was like, is he dropping hints?

00:41:58.000 --> 00:42:07.000
So, yeah, I mean, so many of you're right, like, so part of our paper looks at the way that like assistive technologies have moved from that. You know.

00:42:07.000 --> 00:42:13.000
And this is so much the case with like anything inclusion based right?

00:42:13.000 --> 00:42:14.000
Anything that you do to include people who are the most marginalized benefits.

00:42:14.000 --> 00:42:25.000
Everybody. And this is true, for, like educational contexts, social context, societal contexts, right?

00:42:25.000 --> 00:42:35.000
And it's behind the concept of unal design we're talking about this week, and you know, we can think of like universal design as being for everyone.

00:42:35.000 --> 00:42:44.000
So you have like, like, physical space is easy curbs that have like, you know, slopes right?

00:42:44.000 --> 00:42:53.000
Those cutouts were for wheelchairs or strollers, or bicycles, or skateboards right like that benefit everybody who's walking on the sidewalk.

00:42:53.000 --> 00:43:01.000
Not just people with disabilities, and in so many ways we can think of assistive technologies as doing this.

00:43:01.000 --> 00:43:02.000
And so, you know, audible, you know, started off as an assistive technology.

00:43:02.000 --> 00:43:04.000
But now it's just used by everybody, you know.

00:43:04.000 --> 00:43:13.000
I use it. When I have a long drive, and I don't.

00:43:13.000 --> 00:43:27.000
Wanna here, music. And I wanna read a book, but I can't read 'cause I'm driving, or you know, and so Otter AI is what we're we're focusing on for our paper.

00:43:27.000 --> 00:43:28.000
Do you? Wanna do you wanna share a screen or?

00:43:28.000 --> 00:43:33.000
And and I, yeah, yeah, I could just share.

00:43:33.000 --> 00:43:36.000
So we're going to demo it when we have to.

00:43:36.000 --> 00:43:40.000
But like, I just wanted to. Oops. Sorry, I know. Are you able to see this?

00:43:40.000 --> 00:43:41.000
Yes.

00:43:41.000 --> 00:43:42.000
This is a okay. So this is my dashboard. So it's free you can sign up for it for free.

00:43:42.000 --> 00:43:54.000
Actually, it's pretty cool, and I think that because I'm an educator, though, because, Adam, I do, you have the same.

00:43:54.000 --> 00:43:57.000
Do you have the same permissions that I have?

00:43:57.000 --> 00:44:17.000
I was not. I had to get well. So I'm not sure, because I try to connect Otter, so you can integrate it with Zoom, and I try to integrate it through our Sfsu account, and then my company account and neither of all both of those required a like an

00:44:17.000 --> 00:44:18.000
Hmm!

00:44:18.000 --> 00:44:19.000
Yeah.

00:44:19.000 --> 00:44:20.000
administrator to approve it, and it seemed like what ever your foothill Community College district didn't require that.

00:44:20.000 --> 00:44:24.000
So maybe it is because you're a teacher.

00:44:24.000 --> 00:44:31.000
Yeah, I think it's probably because I'm a teacher, and maybe my district already subscribes to it without me knowing.

00:44:31.000 --> 00:44:47.000
But like, for example, like this, is my regular class that I teach, and I haven't tried it with my regular class yet, but like it allows you to integrate it with zoom, which I'm I'm not.

00:44:47.000 --> 00:44:56.000
I obviously like, if I were the host of today's meeting, I could integrate it I like I could show you how it looked as if I were the teacher using auto AI.

00:44:56.000 --> 00:45:02.000
But because that's not the case. I I'm still the student like I could use as a student would.

00:45:02.000 --> 00:45:11.000
And so the way that it would work is that of your student you could actually use about 3. What was it, Adam?

00:45:11.000 --> 00:45:12.000
Yeah, I think it's 300 min. Yeah.

00:45:12.000 --> 00:45:18.000
Do you remember? Like 300, something minutes of recording 300 min of recording for free before you had to upgrade?

00:45:18.000 --> 00:45:19.000
But if you're a student with a learning disability, whose institution uses auto AI, you can actually probably have free access.

00:45:19.000 --> 00:45:32.000
Also through Dss. But 300 min is a good amount of time, you know.

00:45:32.000 --> 00:45:36.000
The thing is, you have to kind of consider the fact that, like this is ultimately a recording device, right?

00:45:36.000 --> 00:45:43.000
So like, I'm gonna go ahead and just does anybody mind if I record to show how this works?

00:45:43.000 --> 00:45:49.000
And it's okay. If you do mind.

00:45:49.000 --> 00:45:51.000
You're getting thumbs up in in the.

00:45:51.000 --> 00:45:52.000
Okay. I can't see. So I'm just gonna go ahead and record this so that you can hear.

00:45:52.000 --> 00:46:01.000
Or you can see as it's transcribing the conversation.

00:46:01.000 --> 00:46:07.000
Hey? If somebody else wants to say something right now.

00:46:07.000 --> 00:46:12.000
It looks better than Zoom's auto translation.

00:46:12.000 --> 00:46:16.000
Absolutely it does. I don't know why it's not hearing.

00:46:16.000 --> 00:46:19.000
You maybe it's because I have. My is when we tried it before.

00:46:19.000 --> 00:46:20.000
It was not.

00:46:20.000 --> 00:46:24.000
Huh? Oh, that probably. Yeah, that probably. Is it?

00:46:24.000 --> 00:46:25.000
Yeah.

00:46:25.000 --> 00:46:26.000
You know what? Okay, let me.

00:46:26.000 --> 00:46:28.000
It's taking different inputs.

00:46:28.000 --> 00:46:32.000
Let me take off my headphones and see if that works.

00:46:32.000 --> 00:46:36.000
Probably has to come into your microphone.

00:46:36.000 --> 00:46:37.000
There we go!

00:46:37.000 --> 00:46:38.000
Yeah, see?

00:46:38.000 --> 00:46:42.000
There it is!

00:46:42.000 --> 00:46:43.000
Okay.

00:46:43.000 --> 00:46:44.000
Because, yeah, and that's the that's the reason to get Zoom integrated with every single account.

00:46:44.000 --> 00:46:46.000
Cause, then it could intake it that way.

00:46:46.000 --> 00:46:48.000
I'm I'm just gonna pause.

00:46:48.000 --> 00:46:56.000
The recording really quickly. Give me 1 s. Give me 1 s because I have to find my headphone case.

00:46:56.000 --> 00:47:06.000
Is anyone ever else heard of Otter AI, or use it that you know, use it on their campus, or anything.

00:47:06.000 --> 00:47:15.000
I know we have some faculty who use it themselves. I don't think our university supports it, though I haven't really looked at that, but I the chair of our Academic Senate.

00:47:15.000 --> 00:47:20.000
I've mentioned something about auditorium. AI. And he said, Yeah, he uses it all the time.

00:47:20.000 --> 00:47:23.000
You know, to support his own work.

00:47:23.000 --> 00:47:27.000
Cool so you could see like it's taking different.

00:47:27.000 --> 00:47:29.000
You know it's listening into the meeting.

00:47:29.000 --> 00:47:36.000
Ultimately, it's a recording like. So I'll show you when we when we play it back, you can actually hear it.

00:47:36.000 --> 00:47:41.000
You can hear the recording, but you can do all the other cool things with Adam.

00:47:41.000 --> 00:47:44.000
Do you wanna talk about what you can do with it?

00:47:44.000 --> 00:47:45.000
Yeah, so what it? I think, what makes it a big differentiator from?

00:47:45.000 --> 00:47:49.000
Cause like zoom. Does this already? Right? I mean, even if it doesn't do it.

00:47:49.000 --> 00:47:53.000
Well, it's like, I think, what makes this like emerging for our context in online learning is that it kind of packages both.

00:47:53.000 --> 00:48:05.000
It the transcription with more with engagement, tools.

00:48:05.000 --> 00:48:18.000
So you'll see on the right side Marty could then start to as a both live and asynchronously can start to highlight things and then comment on those.

00:48:18.000 --> 00:48:22.000
And there's a chat feature, and then there's like in a task assignment thing.

00:48:22.000 --> 00:48:38.000
So what you could. I think? What makes this like? I was also thinking about this, especially for, like high flex learners, is that like, if you attend asynchronously, you're just kind of watching a recording, there's like a social annotation component to even bring in like what adrian had

00:48:38.000 --> 00:48:59.000
with hypothesis. Students could then start to engage more with with asynchronous learning on if you were to integrate it with this environment, and there's also a way to do like automatic slide capture, so that the transcript would line up with slides as well, so that's

00:48:59.000 --> 00:49:04.000
also really cool, feature.

00:49:04.000 --> 00:49:21.000
Right, and usually the slide capture is like, if if you are using it as your zoom assistant, so for me, if I am a teacher and I'm delivering a lecture, and I'm using as my zoom assistant or something like I can it automatically actually captures my screen every

00:49:21.000 --> 00:49:23.000
few seconds. And it's even better if I'm like.

00:49:23.000 --> 00:49:25.000
I have my own slides. Then it's captures my screen.

00:49:25.000 --> 00:49:44.000
Every every few seconds, and and then you can kind of go back and you have those slides, and people can comment on them, or, you know, addict even.

00:49:44.000 --> 00:49:50.000
They can even add photos to to the notes.

00:49:50.000 --> 00:49:57.000
So it does become like a very social kind of experience, but also really becomes very customizable to the learner.

00:49:57.000 --> 00:50:13.000
If a learner needs to include a visual, to make sense of notes, or you know, if it's a chemistry class, or like a bioclass, or you need a picture of a bio class, or you need a picture of what the lectures

00:50:13.000 --> 00:50:16.000
describing you.

00:50:16.000 --> 00:50:24.000
Alright. So I'm gonna I'm gonna just stop it from recording.

00:50:24.000 --> 00:50:36.000
See if I'm gonna stop share, and I'm gonna stop it from recording.

00:50:36.000 --> 00:50:37.000
Yeah.

00:50:37.000 --> 00:50:43.000
So it it it can looks like you can also assign you gotta talk more about this next week, I know, like the assign you can assign tasks to various comments you're making or highlights, you know.

00:50:43.000 --> 00:50:44.000
Yeah.

00:50:44.000 --> 00:50:46.000
So you you can use it to help you kind of understand.

00:50:46.000 --> 00:50:50.000
Maybe the work you have to do. Yeah.

00:50:50.000 --> 00:50:53.000
So we have a like a personal task organizer idea.

00:50:53.000 --> 00:50:54.000
Yeah, and the really interesting thing about this technology is that it is it's to.

00:50:54.000 --> 00:51:05.000
So again it developed. It was originally it still is an assistive technology, right?

00:51:05.000 --> 00:51:06.000
So you know a lot of the way I found out about it is, I went to a training for my college.

00:51:06.000 --> 00:51:15.000
Can you college for disability services for like technology that helps students with note taking.

00:51:15.000 --> 00:51:25.000
And and this is just one of many, different assistive technologies.

00:51:25.000 --> 00:51:29.000
For note taking, but it was like the one that was most recommended.

00:51:29.000 --> 00:51:37.000
But it also has this newer. It was. It was like magic cause I was telling.

00:51:37.000 --> 00:51:42.000
Adam was like. It was almost like magic cause I had just gone to the training, and then I was like driving in my car.

00:51:42.000 --> 00:51:47.000
Obviously I listened to Npr a lot sorry I'm nerdy and middle aged and like I'm listening to.

00:51:47.000 --> 00:51:48.000
Npr on my way to like drop my kid off from school to school, and it comes on the radio.

00:51:48.000 --> 00:52:18.000
And it's like, Oh, Otto AI is now automate and making meetings like taking the mental load out of meetings, cause it can become your assistant for meetings so like they're marketing it for a mainstream audience.

00:52:26.000 --> 00:52:27.000
Yeah.

00:52:27.000 --> 00:52:29.000
To help people attend meetings and take notes of meetings and then assigns to do tasks for meetings and their newer product is actually deploying your auto AI assistant to attend meetings for you so I don't know how that'll work yet.

00:52:29.000 --> 00:52:36.000
But like you could actually schedule it to attend a meeting for you instead of being there.

00:52:36.000 --> 00:52:41.000
So I don't know how much that would fly with any company, but like it's there.

00:52:41.000 --> 00:52:45.000
So that's the next thing. Okay, I'm gonna.

00:52:45.000 --> 00:52:53.000
Yeah. So then you can attach avatar and the whole works in the in the virtual space.

00:52:53.000 --> 00:52:56.000
Alright. Well, I look forward to hearing more about it. You know.

00:52:56.000 --> 00:53:01.000
I wonder I I don't know if I don't think our university has this for us.

00:53:01.000 --> 00:53:08.000
But the point, the point I was making earlier is that a lot of these technologies design for assistive technologies.

00:53:08.000 --> 00:53:17.000
Have uses now in lots of different places. This is a this is the website for our disability programs and resource center kind of an old name.

00:53:17.000 --> 00:53:33.000
But it's the name that we've had for a long time on our campus, and we've we've been on the forefront for a lot of things, especially around research around disability, you know, kind of resources and things like that in services.

00:53:33.000 --> 00:53:34.000
I mean, it's kind of a it fits with the San Francisco State kind of ethos around social justice and equity.

00:53:34.000 --> 00:53:48.000
And we have. We have the Longmore Institute for disability there's another name for disability studies.

00:53:48.000 --> 00:53:57.000
Maybe Paul Longmore was a long, you know, a long time fundamental, not advocate for making things accessible in real life.

00:53:57.000 --> 00:54:11.000
It just passed away a couple of years ago, but was, you know, back in the the sixties and seventies and eighties, the demonstrations, and did a lot of work with in Berkeley and here in San Francisco, and so we have a long history of that as

00:54:11.000 --> 00:54:17.000
far as the technologies that we use in our on our campus they're they're pretty standard things.

00:54:17.000 --> 00:54:22.000
They focus a lot on like screen readers. Big, big thing for screen readers.

00:54:22.000 --> 00:54:28.000
Translation, materials, things like that occurs, while 3,000 a literary software that we can find on campus pretty much anywhere in students who need this kind of technology to support their account.

00:54:28.000 --> 00:54:34.000
You know, as part of their accommodation for their registered disability.

00:54:34.000 --> 00:54:38.000
You know, can get access to this and have free licensing.

00:54:38.000 --> 00:54:45.000
But students have to have to self, identify and have have to know.

00:54:45.000 --> 00:54:50.000
They have a challenge, and then they have to be able to, you know, provide documentation to the university.

00:54:50.000 --> 00:55:00.000
So the University can put them on a list, and that list it can be communicated to faculty who have them in their classes, and so that's actually that could be quite burdensome for some students, and also it's may not be exactly an equitable situation for those students.

00:55:00.000 --> 00:55:17.000
Also. So the more we can get to software that is more ubiquitous and is less kind of like embedded in the natural experience of the classroom learning experience for the students, the much better off.

00:55:17.000 --> 00:55:23.000
I think students are. Yes, exactly lots of different hardware, smart pens.

00:55:23.000 --> 00:55:25.000
You probably seen smart pens that they can take notes and can record it, and they can.

00:55:25.000 --> 00:55:32.000
Now with digital paper, it can actually put them in digital forms as well.

00:55:32.000 --> 00:55:33.000
Lots of different things, different locations on campus. We also have this.

00:55:33.000 --> 00:55:38.000
They also have this accessible technology resources page.

00:55:38.000 --> 00:55:43.000
Dr. Median, still saying, the the eighth d. 4 on your screen.

00:55:43.000 --> 00:55:49.000
Oh, yeah, I shared the wrong one. There you go. Thank you for letting me know.

00:55:49.000 --> 00:55:52.000
Which one am I supposed to be sharing this one?

00:55:52.000 --> 00:56:04.000
There it is! So I was looking at this page over here, and before that I was looking at this page the disability programs resource center, which is in the Student Services Bill.

00:56:04.000 --> 00:56:10.000
And then our assistive technology page, you can find all this and assistive technology resources.

00:56:10.000 --> 00:56:11.000
And then they have some basic, you know, this is, these are technology that they have available easily.

00:56:11.000 --> 00:56:14.000
This accessible media, quick converter is something that I use as a faculty member.

00:56:14.000 --> 00:56:21.000
And what this does, it allows me to update a file that is not acceptable.

00:56:21.000 --> 00:56:28.000
In other words, it doesn't have all the right, you know.

00:56:28.000 --> 00:56:29.000
Styles identified, it could be it could be.

00:56:29.000 --> 00:56:43.000
I do this a lot for Pdfs that are not text-based Pdfs, it could be it could be. I do this a lot for Pdfs that are not text-based.

00:56:43.000 --> 00:56:52.000
Pdfs their image based. Pdfs, so like, if I scan an older document on an older scanner that doesn't do text recognition, it just gives me an image file which is fine. If you just have to read it on a screen, and you can see it visually but if

00:56:52.000 --> 00:56:53.000
you want us. If you want to select any text, or if you need a screen, reader, to read it to you rather than you reading it with your eyes.

00:56:53.000 --> 00:56:59.000
That's up won't work at all. It's just an image, and there's no alt text.

00:56:59.000 --> 00:57:04.000
How could it be like 10 pages? So this will do a conversion, and it does it really, really, very quickly?

00:57:04.000 --> 00:57:11.000
I upload the Pdf in the image file it sends it back to me in a text file, and it's done.

00:57:11.000 --> 00:57:15.000
It does a pretty good job. It does a pretty good job without making lots of errors.

00:57:15.000 --> 00:57:16.000
A few errors. Of course, that's not perfect.

00:57:16.000 --> 00:57:21.000
And so it's, it's a tool that allows us to be to be better at creating accessible materials, so that the technology can actually read the content to the students.

00:57:21.000 --> 00:57:40.000
Because if you've got all the accessible technology that you think you need, but that the source documents are not able to be read by that technology, it's kind of useless right right?

00:57:40.000 --> 00:57:48.000
And that has happened, and one of the reasons I started doing this was not because I had students who needed to use screen readers least.

00:57:48.000 --> 00:57:52.000
Not that I knew of, but I had students who wanted to highlight text in a reading that I had assigned to them, so that they could highlight it.

00:57:52.000 --> 00:58:07.000
Mark it up for themselves, or maybe even copy and paste into notes that they were taking for themselves, or maybe a quotation they wanted to do, for I know for a paper they were writing, or something like that.

00:58:07.000 --> 00:58:21.000
And I didn't realize that that that that was a used case, and that was one reason to go through and make sure that that all the text documents I share are actually text texts, not image text.

00:58:21.000 --> 00:58:24.000
So that's a that was, I remember that was the case.

00:58:24.000 --> 00:58:31.000
I think it was I take 800 where that happened probably about 2 years ago, 2 or 3 years now, whatever it was, could have been 1 3 years ago.

00:58:31.000 --> 00:58:34.000
This is what I started teaching that class. So yeah, anyway, accessible technology.

00:58:34.000 --> 00:58:39.000
Let's.

00:58:39.000 --> 00:58:42.000
You could. There's more that you can read and explore on that.

00:58:42.000 --> 00:58:45.000
Of course we want to talk a little bit about personal learning environments, too.

00:58:45.000 --> 00:58:56.000
But let's take a little break first. Let's just take a little break first.

00:58:56.000 --> 00:59:04.000
Okay, I'm gonna start the recording back at it. Well, come back from your short break.

00:59:04.000 --> 00:59:07.000
Let's talk about personal learning environments for a few minutes.

00:59:07.000 --> 00:59:21.000
And then I'm gonna ask you to share your own or come up with one in a little breakout and we'll see what some of our personal learning environments might look like.

00:59:21.000 --> 00:59:27.000
I gave you a couple of simple read. Well, one simple reading one that'll be more complicated reading that talks about research around personal learning environments.

00:59:27.000 --> 00:59:39.000
This. This is a style of article, short old article, a little brief, that educause does 7 things you should know about whatever, and then a different topics.

00:59:39.000 --> 00:59:44.000
They've done. I wrote one for them on High Flex a number of years ago.

00:59:44.000 --> 00:59:49.000
Someone rewrote it about a couple of years ago, during the pandemic but there's lots of different things.

00:59:49.000 --> 00:59:53.000
They like the 7 things you should know about. And so this kind of does a summary just says, Okay, what?

00:59:53.000 --> 00:59:56.000
What's the situation? What's the solution?

00:59:56.000 --> 00:59:57.000
What's what's the technology involved here?

00:59:57.000 --> 00:59:58.000
What is it? Who's doing it? etc.

00:59:58.000 --> 01:00:07.000
Could be an approach right. And so this was supposed to give you a brief little overview on personal learning, environments, personal learning, environments.

01:00:07.000 --> 01:00:10.000
Which have gone from this concept of people thinking about, how do we develop a personal learning environment?

01:00:10.000 --> 01:00:23.000
Can we give students a personal learning environment like create a platform of all the different technologies they would need to be to support their learning in a particular.

01:00:23.000 --> 01:00:33.000
You know situation, or on the other side of this, is totally totally not systemic, I guess, but it's more of a completely individual.

01:00:33.000 --> 01:00:37.000
What do you use to do? The various things you use to live your life?

01:00:37.000 --> 01:00:40.000
Now, if you want to think about the students, what do you use as a student?

01:00:40.000 --> 01:00:48.000
Right, or as a teacher? Or as a professional. What are you using your professional, personal learning, environment, enlisting all the different technologies, aligning them up with the different tasks and functions that that they support you?

01:00:48.000 --> 01:01:06.000
With. So you have a kind of a map, you can create a map, maybe visual representation of this learning network or environment, a technology enabled environment that supports whatever it is. You're focused on.

01:01:06.000 --> 01:01:12.000
By taking a look at that you might be able to look sometimes you you can look at it with an eye towards design.

01:01:12.000 --> 01:01:19.000
Well, it looks like there's not a lot of stuff in your personal learning environment that supports this kind of function.

01:01:19.000 --> 01:01:20.000
Perhaps this is something that you would want to develop further. Maybe we could suggest some tools in that sense.

01:01:20.000 --> 01:01:27.000
You could talk to students about this, you could see what they're doing.

01:01:27.000 --> 01:01:33.000
Naturally, or you could kind of give them some tools to use and see how that would fit in. Adam.

01:01:33.000 --> 01:01:41.000
I was in reading this, and it could be that I'm like so immersed in my career, in blended learning that it was.

01:01:41.000 --> 01:01:47.000
And then like this, especially this course is somewhat blended.

01:01:47.000 --> 01:02:03.000
I would say that there's some like independent acronyms, learning facilitated by synchronous learning, that, and like access to different tools to access these resources, that, like it, seems like.

01:02:03.000 --> 01:02:19.000
We are moving more and more towards the the futures that these articles were kind of talking about, that were with online learning and more distance learning for everyone.

01:02:19.000 --> 01:02:26.000
We're all personalizing learning experience as learners somewhat for ourselves, because we're doing it at home.

01:02:26.000 --> 01:02:39.000
We're using the various tools that support us to do it rather than like being limited by the classroom environment which inherently makes it less personalized for some students than others.

01:02:39.000 --> 01:02:54.000
Yeah, definitely. You know, I think if if you think about the learning environments that you use it like in your work life, you probably have a set of learning, a set of technologies that you use because your work supports those and expects you to use these technologies, for various

01:02:54.000 --> 01:02:58.000
functions, maybe there's a certain way you communicate with the people you're working with.

01:02:58.000 --> 01:03:02.000
Maybe the way you create materials uses particular.

01:03:02.000 --> 01:03:07.000
You know, expectations around the technologies that you're using you know how that's community.

01:03:07.000 --> 01:03:09.000
How do you work with clients? All that kind of stuff?

01:03:09.000 --> 01:03:18.000
And yet all around that are other technologies that you use that supplement those and do other things that aren't necessarily work driven, but still support work.

01:03:18.000 --> 01:03:26.000
For example, you might use a you might use an instant messenger platform to communicate with people that's not necessarily supported by your your local. It group.

01:03:26.000 --> 01:03:30.000
But say, Hey, yeah, you wanna use it fine. Go ahead on our campus.

01:03:30.000 --> 01:03:39.000
We use tools like slack or disorder, things like that not supported by the institution, but a lot of people use them in their work or with with in in our work of teaching, even with their own students.

01:03:39.000 --> 01:03:49.000
And so there's that element of like system support supplied, and that you will use it an expected way, and then you might supplement with that, with other things.

01:03:49.000 --> 01:03:57.000
But you can also find that you might use the tools that are provided to you for a particular function in different ways themselves.

01:03:57.000 --> 01:04:08.000
Right, especially when we have tools with very rich capabilities, like Microsoft teams, mean, we have Microsoft teams available to us on our campus, a lot of academics don't use it, but a lot of a non academics use it all the time.

01:04:08.000 --> 01:04:09.000
And that's their web conferencing of choice.

01:04:09.000 --> 01:04:21.000
And it's got like 6 or 7 other major applications that are that are tightly connected right into that around messaging and communication.

01:04:21.000 --> 01:04:22.000
So so there's a lot of variety there, too.

01:04:22.000 --> 01:04:30.000
Some use it for certain things, and not for others. You might find that you use a couple of different email systems.

01:04:30.000 --> 01:04:36.000
How many email systems do you use? I use it least 3, maybe even 4, dependent behind you. Count them for different reasons.

01:04:36.000 --> 01:04:43.000
I've got my work, my teaching and learning email, which is also a large part of my professional email on the academic side.

01:04:43.000 --> 01:04:44.000
But I also have. I have several different Gmail accounts used for different purposes, and I have.

01:04:44.000 --> 01:05:07.000
I have, I have a you know, I have a website that has another email account that I use for administrative purposes for the administration of the website.

01:05:07.000 --> 01:05:08.000
Hmm!

01:05:08.000 --> 01:05:09.000
And so even an email, I could see at least 5 or 6 different email but it can get pretty complicated, depending upon you know how you structure this.

01:05:09.000 --> 01:05:19.000
So you have one. You're students have one.

01:05:19.000 --> 01:05:25.000
The people you work with have one, you're the people you're training, especially if you're doing ongoing support for a group of people.

01:05:25.000 --> 01:05:30.000
They've got their own personal learning networks or environments, you know, networks, environments like they're not the same, but they're certainly related.

01:05:30.000 --> 01:05:54.000
And I think it's important to take a look at that and try to understand that any comments about, please. In general, I'm gonna ask you to kinda start exploring this with, you know, one or 2 other people here in more detail and just a second.

01:05:54.000 --> 01:05:55.000
Alright. Well, what? Here's what we're gonna do next. Go ahead.

01:05:55.000 --> 01:06:05.000
I guess I just. Had one question just to follow by other one.

01:06:05.000 --> 01:06:06.000
Oh, yeah. Yeah. Alright.

01:06:06.000 --> 01:06:13.000
Would you say, Doctor B, that the article like? Because the articles that were there wasn't was from like 2,009, I think it was from 2,014 that they're like that we are now towards like 10 years later.

01:06:13.000 --> 01:06:16.000
Now we're towards a future that is like it was less the case when those articles came out, and we have all more personalized our environments.

01:06:16.000 --> 01:06:23.000
Now than we had 10 years ago.

01:06:23.000 --> 01:06:24.000
Yeah, I think, especially the 2,009, I think. Back then I remember those days.

01:06:24.000 --> 01:06:26.000
They were talking more about, how do we build a account?

01:06:26.000 --> 01:06:41.000
Personal learning, environment, to support students. And I think the realization over the next 5 or 10 years really, well, actually, the personal learning environment is being built.

01:06:41.000 --> 01:06:47.000
But we're not building it. It's being built by the kinds of technologies that they're being one.

01:06:47.000 --> 01:06:51.000
We're giving the Lms tool sets we give them are one part part of that.

01:06:51.000 --> 01:07:00.000
But all the social media tool sets that they're getting from outside and beginning to use more integrated with their learning process I mean, that's part of it, too.

01:07:00.000 --> 01:07:02.000
And then everything else that they might bring in on the side.

01:07:02.000 --> 01:07:03.000
Right.

01:07:03.000 --> 01:07:04.000
There was a time when we had all these conversations about.

01:07:04.000 --> 01:07:20.000
Well should you know, for example, should we use Google, you know, to we use Gmail at the University, and one of the arguments against using Gmail is because, while a lot of people are using it for the personal accounts, and if we start using it for the professional communications to now we

01:07:20.000 --> 01:07:24.000
don't have that separation, and there are some people who like to have that separation.

01:07:24.000 --> 01:07:29.000
I think that's probably not nearly as much of a thing as it was back then.

01:07:29.000 --> 01:07:34.000
I think there's probably more Melding now than before, I mean, that's just my feeling, because I knew it myself.

01:07:34.000 --> 01:07:43.000
More I'm sorry. Say, yeah, connected by Google, yeah. Connected by Google it's a hall becomes a, you know, kind of this mess.

01:07:43.000 --> 01:07:53.000
Useful. Mess, usually, so, yeah, I think we've gone away, for I think we're going away from the idea of a a system that is a personal learning environment.

01:07:53.000 --> 01:07:57.000
That was a big deal back in those days.

01:07:57.000 --> 01:08:02.000
Now it's more of a it's gonna look differently for everybody to be some commonalities.

01:08:02.000 --> 01:08:09.000
And still some differences. I there's not no one in here has exactly the same personal learning environment as anyone else.

01:08:09.000 --> 01:08:12.000
Probably anywhere in the world.

01:08:12.000 --> 01:08:29.000
Even if we gave you the same phone and the same laptop, or whatever, and give you the same set of tools to use here, you would still the way that the way the technology is built these days, you can still find ways to individualize it you add apps, you know and if you can configure apps

01:08:29.000 --> 01:08:34.000
differently to will this app I have this app that gives me it gives me messages.

01:08:34.000 --> 01:08:36.000
It gives me notifications. Well, I don't have that.

01:08:36.000 --> 01:08:40.000
I don't have that turned on. So you use that app a little differently, and it communicates to you differently.

01:08:40.000 --> 01:08:44.000
I don't want an app that's telling me every 10 min oh, there's someone there's some motion in your front yard, or there's some motion in your backyard, you know.

01:08:44.000 --> 01:08:52.000
Other people might want that, or I don't want an app that every time I get email says, Oh, you've got an email.

01:08:52.000 --> 01:08:53.000
Oh, you've got an email. Oh, you've got an email.

01:08:53.000 --> 01:08:55.000
Oh, you've got an email. Other people want that right?

01:08:55.000 --> 01:09:02.000
So even those have an influence on your personal learning environment. And you know it's it.

01:09:02.000 --> 01:09:05.000
I think it's something that's worth looking at.

01:09:05.000 --> 01:09:10.000
Okay, let's do a little exercise for this. What I'd like you to do is to take at least one of you or or you'll pick a learner, maybe a representative.

01:09:10.000 --> 01:09:19.000
Learned you could pick yourself. If you want and create a personal learning environment.

01:09:19.000 --> 01:09:20.000
If you want to, if you create one for someone else, just think, put yourself in their situation and kind of think through.

01:09:20.000 --> 01:09:30.000
Like a port. Sona idea, what would it? What's their life like as as a learner right?

01:09:30.000 --> 01:09:39.000
What kinds of things are they gonna be asked to do? What's their situation and just kind of create a like a persona driven personal learning, environment that way, you could do something that's not one of you.

01:09:39.000 --> 01:09:56.000
But you could use yourself as a persona, too. Okay? And then think about and bring in some of the elements that we just talked about as assessed to learning and identify the technologies you see there that could actually be fulfilling some sort of an assistive role you know maybe they're not

01:09:56.000 --> 01:10:01.000
labeled as a system technology, but they could certainly be used that way.

01:10:01.000 --> 01:10:05.000
Alright, and you can create a diagram. I think you should be able to.

01:10:05.000 --> 01:10:22.000
You can create a diagram here in the notes, probably not as easy in the notes, but maybe another piece of software, part of your personal learning environment for building stuff and link it in or copy and paste an image you can export an image, or something like that does that make sense.

01:10:22.000 --> 01:10:25.000
And then we'll use those to kinda talk through the concepts a little bit more.

01:10:25.000 --> 01:10:26.000
So if we want any time for talking, how much time do you think this will take? 20 min?

01:10:26.000 --> 01:10:35.000
Maybe let's try. Let's start with 20 min way says 15.

01:10:35.000 --> 01:10:38.000
Okay. So in her group, they're gonna go really fast.

01:10:38.000 --> 01:10:39.000
Maybe you could do 2, and looks like we have 9 people besides me.

01:10:39.000 --> 01:10:42.000
Hmm.

01:10:42.000 --> 01:10:48.000
And so we'll do 3 groups, 3 groups of 3, and we'll just kind of randomly assign you.

01:10:48.000 --> 01:10:55.000
Of course, and thank you, Linda. You put the Google Doc link in the chat so everyone can see it click on it.

01:10:55.000 --> 01:10:57.000
If you want to. It's also available. Of course, in the Lms.

01:10:57.000 --> 01:11:06.000
It's just not always conveniently connected and I'm going to create the breakouts, and I will check in with you in 15 min, and if everyone's done we'll come back.

01:11:06.000 --> 01:11:11.000
Otherwise we'll give you another 5.

01:11:11.000 --> 01:11:12.000
And I'll be pausing. The recording while we're doing this.

01:11:12.000 --> 01:11:18.000
Okay. See you soon.

01:11:18.000 --> 01:11:19.000
Let's start the recording, and then we'll hear from your groups and see what you came up with.

01:11:19.000 --> 01:11:23.000
Alright! We're welcome back for the one or 2 of you watching the recording.

01:11:23.000 --> 01:11:29.000
I was just looking at the Zoom recording logs. I tell you it's kinda depressing.

01:11:29.000 --> 01:11:39.000
If you're expecting everybody who's not here live to be watching those videos every week I don't know what you get from 15 min or 10 min or 7 min, but it's better than nothing, I guess.

01:11:39.000 --> 01:11:43.000
Anyway, that's not what we're talking about. It is part of our Poe right?

01:11:43.000 --> 01:11:49.000
But we're gonna we're gonna talk with Group 2 first and say, we're first ones back.

01:11:49.000 --> 01:11:53.000
What did you come up with? A personal learning environments?

01:11:53.000 --> 01:11:56.000
Oh!

01:11:56.000 --> 01:11:57.000
So it's our group.

01:11:57.000 --> 01:11:59.000
Yeah, it's your group.

01:11:59.000 --> 01:12:04.000
Oh, okay, I'll book over use my example. Then we are discussed about this.

01:12:04.000 --> 01:12:16.000
I teach mandarin in a high school, and in my class I usually have, like a 25 to 30 students.

01:12:16.000 --> 01:12:22.000
I will say 2 third of them are in higher level class, 2 third of them.

01:12:22.000 --> 01:12:34.000
Heritage family speaker. There means their parents. Maybe grandparents speak mandarin, but another one third of students.

01:12:34.000 --> 01:12:39.000
They are not like Indian students, Latino students, black students. They don't have any language support at home.

01:12:39.000 --> 01:12:56.000
So like these students that we, I usually give more attention. I will design a situation like one student who is a non Chinese heritage speaker at home, who is struggling in the classroom.

01:12:56.000 --> 01:13:05.000
Especially struggling, memorize the grammar, rule and memorize the vocabulary.

01:13:05.000 --> 01:13:12.000
So we draw. We draw the diagram, and we thought about a couple ways.

01:13:12.000 --> 01:13:17.000
The first is a traditional way tutoring, but we can tutoring.

01:13:17.000 --> 01:13:18.000
We can try use AI tutor. So I don't know what tool.

01:13:18.000 --> 01:13:34.000
But I'm just thinking that way. There are one way I can, or we can try AI tutor or another way is 1 one in person or on zoom personal tutor.

01:13:34.000 --> 01:13:39.000
And in the middle you can see we use the multimedia like learning the stuff, not watching a movies movie and watching the TV show start.

01:13:39.000 --> 01:13:53.000
Also, we can use the social media like their Instagram, awesome.

01:13:53.000 --> 01:13:58.000
Class group social media stuff, and the last one we thought about.

01:13:58.000 --> 01:13:59.000
If we have to use one technology, I would like to try.

01:13:59.000 --> 01:14:03.000
That this student install dual go on his platform.

01:14:03.000 --> 01:14:15.000
Like to try. Let these students install dualing go on his platform. So when when we talk about one topic and I will find it, I will help this to find that this topic related.

01:14:15.000 --> 01:14:23.000
Games on to Ringo, and this kid. We are just a practice.

01:14:23.000 --> 01:14:31.000
When playing games.

01:14:31.000 --> 01:14:40.000
Yeah, that is hmm. Our discussion, Andrea, do you have anything to add?

01:14:40.000 --> 01:14:51.000
No, thank you for sharing your example. Let us use her whole scenario, so that was help.

01:14:51.000 --> 01:14:55.000
Yeah, obviously, you know, 20 min isn't enough time to fully explore this.

01:14:55.000 --> 01:14:59.000
But you've got a good start here at the very various topics here.

01:14:59.000 --> 01:15:08.000
Do you think that the students themselves would bring in their own technologies to support the design that you're creating for the environment?

01:15:08.000 --> 01:15:14.000
Would that be expected of you, or is that not something you'd expect?

01:15:14.000 --> 01:15:21.000
I haven't a choice, but I think if I give them examples, they will find more stuff than me.

01:15:21.000 --> 01:15:31.000
Uhhuh, yeah. So for example, if you get them using Duolingo or an app like that, do you think that's likely that some of them would look for other apps on their own?

01:15:31.000 --> 01:15:35.000
You know mango, or if there's there's a whole bunch to them.

01:15:35.000 --> 01:15:42.000
I imagine, then, probably some that are specific to a language is that the is that the kind of student you would expect?

01:15:42.000 --> 01:15:44.000
No, I don't think so.

01:15:44.000 --> 01:16:00.000
Oh, okay. Okay. Alright. That's good to know, because it mean that if you have students who you who, if you know that they are the ones who are likely that they're going to find their own resources to help, then then your task's a little different, it's like okay.

01:16:00.000 --> 01:16:16.000
give them the core, you know that you gotta have something that does something like this, and if you don't have your own, here's one you can use but then you kind of make it so that your approach to supporting their learning, can be flexible, and I guess agile enough sort of so that if they want to bring in

01:16:16.000 --> 01:16:19.000
a different technology, you're able to do that right.

01:16:19.000 --> 01:16:22.000
But if you don't expect that kind of student, then you really kind of have to make sure.

01:16:22.000 --> 01:16:28.000
Okay, these are the 5 core functions. We need you to be engaged in to learn this.

01:16:28.000 --> 01:16:29.000
And okay, I need to make sure that we are supporting this function.

01:16:29.000 --> 01:16:36.000
And this function in this function and this other function.

01:16:36.000 --> 01:16:45.000
Interestingly enough, there is a there's a short course in you to me, a little online, a little online course, probably free maybe you can get it free trial.

01:16:45.000 --> 01:17:03.000
It's about using. Chat Gpt to help people learn languages and how you can actually have use it for conversational platform, you know with these, the AI tools, you can actually have it, you know, talk back and forth with a student in a different language.

01:17:03.000 --> 01:17:11.000
Apparently I haven't tried it myself, but if you search around for resources you might be able to find something pretty interesting.

01:17:11.000 --> 01:17:16.000
Okay. Anything else. From group 2.

01:17:16.000 --> 01:17:25.000
Everett. Is there much talk about going around AI in the history world, in the discipline, especially in the maybe on the writing side, I imagine.

01:17:25.000 --> 01:17:34.000
But anything else like, you know, can these AI tools do like a historical and analysis on a, on a situation or a work?

01:17:34.000 --> 01:17:38.000
So I've noticed it's very limited. I didn't think so at first.

01:17:38.000 --> 01:17:43.000
I cause it just sounded so nice, you know, and it does.

01:17:43.000 --> 01:17:44.000
Yeah.

01:17:44.000 --> 01:17:45.000
It really helps it's helped me a lot I actually really appreciate it.

01:17:45.000 --> 01:17:56.000
I also think it could be used in 2 ways, one, that benefits you and one that doesn't necessarily benefit as much and can keep you limited if you don't.

01:17:56.000 --> 01:17:57.000
Right.

01:17:57.000 --> 01:18:05.000
If you don't recognize that limitation, too. But yeah, I've noticed it more and more, but I do think it's just really it's a helpful tool that it's a helpful.

01:18:05.000 --> 01:18:11.000
You know something that alongside of you know it to assistant tool.

01:18:11.000 --> 01:18:12.000
Yeah.

01:18:12.000 --> 01:18:20.000
Right, yeah, yeah. You know, I think that, you know, looking at the Poe, I concept this year, in the first year of you know, this.

01:18:20.000 --> 01:18:34.000
Really, you know, being kind of dominated a bit by AI, you know, you kind of have to start thinking a little differently about this, because some of these are clearly using AI tools already, and if the ones that are, I mean at some point, you might start seeing more convergent

01:18:34.000 --> 01:18:42.000
even among tools that you wouldn't necessarily think would be, you know, kind of on a path of, you know, like coming together, like, you know, and then say, Oh, my gosh!

01:18:42.000 --> 01:18:47.000
Now it's a new tool and it's doing something we never thought we would even have it do alright.

01:18:47.000 --> 01:18:58.000
Well, let's go on. How about how about group one moving up in the world to the previous page haven't put page numbers on this one yet, I guess.

01:18:58.000 --> 01:19:04.000
Group one. What do you have to say?

01:19:04.000 --> 01:19:07.000
To a spokesperson.

01:19:07.000 --> 01:19:17.000
Okay, sorry. So, yeah, this person is, a 12 year old girl with a passion for drawing.

01:19:17.000 --> 01:19:25.000
It's based on my daughter again. Sorry and her learning environment is home.

01:19:25.000 --> 01:19:31.000
She uses Youtube to learn to draw and speech a text to learn to write in order to create graphic novels.

01:19:31.000 --> 01:19:41.000
She watches different Youtube videos about different techniques of shading outlining, dimensional drying, and has taught herself how to illustrate for animation.

01:19:41.000 --> 01:19:59.000
And her setting is home. Learning characteristic. She's curious, highly motivated for task to interest her, creative, driven by ideas and some of her materials are what we Pasca markers which are kind of like pink markers colored pencils, pens prismacolor and tools for

01:19:59.000 --> 01:20:03.000
learning and practicing, drawing like sketch pads and stuff like that.

01:20:03.000 --> 01:20:04.000
She's never taken a formal art or class.

01:20:04.000 --> 01:20:18.000
So her assistive technology is Youtube or speech to text. And Adam, what I was describing this came up with this idea of of a diagram more picture.

01:20:18.000 --> 01:20:19.000
And she's a she. Yeah, she, I feel like, do you?

01:20:19.000 --> 01:20:25.000
Tube is a, really, I thought, Youtube is its own personal learning, environment.

01:20:25.000 --> 01:20:33.000
How many of us have not have taught ourselves something from watching Youtube.

01:20:33.000 --> 01:20:36.000
You know she's definitely has taught herself how to draw.

01:20:36.000 --> 01:21:04.000
Like I said, from watching to Youtube. But, like, you know, I taught myself different, like things, techniques for beating, for example, that, like are new to me, or like my husband, watches Youtube to learn how to change out a doorknob and then this is a photo like she's

01:21:04.000 --> 01:21:05.000
Nice.

01:21:05.000 --> 01:21:07.000
like okay, you could show them this. I mean, let me unblower it. This is one of her characters that she created dog named Misery.

01:21:07.000 --> 01:21:11.000
And it's and that's her main character.

01:21:11.000 --> 01:21:19.000
And so she like writes this like graphic novel about misery and different adventures that miser gets into.

01:21:19.000 --> 01:21:29.000
But anyway, it's just sort of I what the minute I thought about a learner profile and a plie, I thought about Youtube, which I think also could be its own assistive technology.

01:21:29.000 --> 01:21:39.000
In some ways as well, because it does have captioning with it.

01:21:39.000 --> 01:21:45.000
But nevertheless she'll also use the speech to text as well to create her little.

01:21:45.000 --> 01:21:49.000
Her little books.

01:21:49.000 --> 01:21:52.000
And wouldn't you see, like the way that it auto plays?

01:21:52.000 --> 01:21:59.000
What, based on her interest, also kind of creates this personalized learning, adaptive learning, pathway.

01:21:59.000 --> 01:22:13.000
Yeah, the algorithm, right of Youtube, because when you look up something, it just automatically produces more videos about that thing or different aspects about it, or a lot of content creators will put like lessons like lesson one lesson.

01:22:13.000 --> 01:22:22.000
2. Lesson 3, and then it just automatically queues those lessons for you which is really cool.

01:22:22.000 --> 01:22:24.000
So, yeah.

01:22:24.000 --> 01:22:29.000
How long do you think it will be before Youtube actually starts creating videos for you?

01:22:29.000 --> 01:22:32.000
Not just giving you the next one in a list. But say, oh, you need a 3 min video on this topic.

01:22:32.000 --> 01:22:48.000
Based on what you've been exploring, and then actually uses its AI wonders to find content and make it a new video for you, a real customiz video.

01:22:48.000 --> 01:22:49.000
I would imagine that might be something they'd be working on.

01:22:49.000 --> 01:22:51.000
Oh, I haven't thought about that!

01:22:51.000 --> 01:22:54.000
Imagine that then they don't have to pay any content.

01:22:54.000 --> 01:22:55.000
Creator!

01:22:55.000 --> 01:23:00.000
That's true, and a lot of youtubers would be out of business.

01:23:00.000 --> 01:23:01.000
Yeah. Well, then, I think there'd be this competition, then, between a real Youtuber and an AI youtuber right?

01:23:01.000 --> 01:23:12.000
Yeah, and interesting I hadn't thought about that before. Great!

01:23:12.000 --> 01:23:28.000
Yes, and actually, if if you think about your daughter using Youtube, you can think about okay, what are all the other things that she's using after the same time, or that Youtube then launches a route into this, now, she's developing this or even within Youtube she's using comments

01:23:28.000 --> 01:23:35.000
if she using kind of the, you know, the linking that goes in and out of Youtube as part of the process as as well.

01:23:35.000 --> 01:23:36.000
Are there websites that are being referred to that are part of that?

01:23:36.000 --> 01:23:42.000
And are there multiple references references out among that?

01:23:42.000 --> 01:23:47.000
So you can see how this can easily expand quite quickly.

01:23:47.000 --> 01:23:48.000
Quite quickly.

01:23:48.000 --> 01:23:51.000
Yeah, I think that she definitely depends on the Youtube algorithm. Right?

01:23:51.000 --> 01:23:58.000
Because especially if someone like her who like, you know, the other part of Youtube is like you can dictate what you're looking for.

01:23:58.000 --> 01:24:15.000
So you don't have to type it in so you can press the microphone and say, Show me videos on this, which makes Youtube really easy for kids to access and use, which is also a bad thing.

01:24:15.000 --> 01:24:19.000
It could be a bad thing, but you know.

01:24:19.000 --> 01:24:24.000
But then the algorithm is good, too, because you'll have to just keep searching things right.

01:24:24.000 --> 01:24:29.000
You don't have to keep putting things in the search field, it'll automatically produce it for you.

01:24:29.000 --> 01:24:30.000
Right.

01:24:30.000 --> 01:24:33.000
So!

01:24:33.000 --> 01:24:36.000
Yeah, I, I find some of those tools very useful.

01:24:36.000 --> 01:24:39.000
And I use Youtube for to help me learn what I have to learn. Something.

01:24:39.000 --> 01:24:42.000
That's one of the first things I go to. Someone have a video out there.

01:24:42.000 --> 01:24:46.000
I can watch, you know, especially if it's something that I have to.

01:24:46.000 --> 01:24:50.000
You know, fix something, put something together, or whatever I forget.

01:24:50.000 --> 01:24:57.000
The last thing I look for, but very useful. Okay, thank you.

01:24:57.000 --> 01:25:04.000
Group anyone else from Group One.

01:25:04.000 --> 01:25:11.000
Okay, onto group 3, group 3.

01:25:11.000 --> 01:25:14.000
I guess I'll be the lead for talking about what we're working on.

01:25:14.000 --> 01:25:18.000
We were kind of halfway through by using a whiteboard.

01:25:18.000 --> 01:25:26.000
That's on the zoom. So we forgot to take us.

01:25:26.000 --> 01:25:27.000
Oh, you lost it!

01:25:27.000 --> 01:25:36.000
Take a screenshot or export it, but basically we're talking about our scenario as a student, as a state student, that's, you know, with this strong auditory as like a strong auditory learner.

01:25:36.000 --> 01:25:47.000
So prefers to listening to text, and then some of the applications were taught, and also the students taking in person and also online classes.

01:25:47.000 --> 01:25:50.000
Both.

01:25:50.000 --> 01:26:01.000
So I think a few things we're talking about, like, you know, using Texas speech applications and also we're talking about like donor. Bd, you brought up that the Prc.

01:26:01.000 --> 01:26:06.000
Has the converters that's available to convert image into text.

01:26:06.000 --> 01:26:10.000
So you know, as a student, you can use that to comfort like tech like this.

01:26:10.000 --> 01:26:21.000
Say textbook that, or as Pdf, file or image files like from into text, and using the text to speech, to get like audios.

01:26:21.000 --> 01:26:27.000
And I think we also talk about. You know the student can also utilize zoom recording.

01:26:27.000 --> 01:26:32.000
Just listen to recording and things. Oh, great well brought us up.

01:26:32.000 --> 01:26:38.000
Thank you guys so much. Yeah. And I think I just wanna point out, like, you know.

01:26:38.000 --> 01:26:47.000
Besides, these things are. Be here. I was pointing out, I guess, active current, that Sfa students.

01:26:47.000 --> 01:27:03.000
Us state gateway. It actually has a lot of resources or applications so like let's say, if you need a need to say, if you're using a lot of things with applications or need to file storage space, there's the box that's no for Ssa, students full

01:27:03.000 --> 01:27:13.000
of the drive for cloud storage space. There's the email, you know, students can use it for communications. What else?

01:27:13.000 --> 01:27:18.000
I'm thinking, Yeah, I think, that's it. For a second.

01:27:18.000 --> 01:27:26.000
Think of it on this. Linda and Amanda don't know if anything else you guys wanna add.

01:27:26.000 --> 01:27:27.000
Cool thanks.

01:27:27.000 --> 01:27:28.000
No, I think you covered it pretty well. Thanks, Annie.

01:27:28.000 --> 01:27:32.000
Yeah, my, yeah, I just liked to talk. I wanted to talk a little bit about speech by speech.

01:27:32.000 --> 01:27:35.000
I was really cool. It's kind of what's been like helping me get through.

01:27:35.000 --> 01:27:37.000
Like all of the readings I have to do with all my classes.

01:27:37.000 --> 01:27:38.000
So if you haven't heard about it, you should look it up.

01:27:38.000 --> 01:27:46.000
It allows. It makes everything like it gets everything. The ability to be like, spoken and like listened to.

01:27:46.000 --> 01:27:50.000
So I think it is something you have to pay for. I think you get a discount as students.

01:27:50.000 --> 01:27:54.000
That's a plus. But also, unfortunately, we have to pay for it.

01:27:54.000 --> 01:28:02.000
But you can share accounts, which is what I do, and that's helpful.

01:28:02.000 --> 01:28:15.000
Number one text to speech, reader, so they say, interesting.

01:28:15.000 --> 01:28:16.000
I really like, yeah, there's like different voice options, especially if you like.

01:28:16.000 --> 01:28:17.000
Amanda. Does it sound nice, or than like the the native one in apple got it?

01:28:17.000 --> 01:28:31.000
Purchase it like when I was sharing a transcript of a documentary, we're watching with my eighth graders, and I had it read it, and there's an option for Barack Obama's voice.

01:28:31.000 --> 01:28:34.000
Which the reason I chose that was because he was the one speaking in the movie.

01:28:34.000 --> 01:28:35.000
So it was like funny to like be able to have him speak the script for them.

01:28:35.000 --> 01:28:38.000
So there's lots of different voices. There's like specific people's voices.

01:28:38.000 --> 01:28:46.000
And then there's also like people with like you can like, choose specific accent, or like, you could choose.

01:28:46.000 --> 01:28:55.000
But it does definitely sound more human than like all the other ones that I've experienced, which is why I like it the most, because I can't really like.

01:28:55.000 --> 01:29:01.000
I don't comprehend things as well when it sounds like robotic, so.

01:29:01.000 --> 01:29:04.000
Hmm!

01:29:04.000 --> 01:29:09.000
And it has a text. I see it has extensions right in like to chrome that makes so much.

01:29:09.000 --> 01:29:14.000
Yeah, I can actually share my screen if you want, really, quick.

01:29:14.000 --> 01:29:15.000
Sure!

01:29:15.000 --> 01:29:23.000
Okay, cool. Let me pull out. First.

01:29:23.000 --> 01:29:30.000
Unmute. Okay? So, I'll go to what it looks like for me when I log in.

01:29:30.000 --> 01:29:35.000
Okay, so if I share, yeah. So this is what my I share with my mom and my sister.

01:29:35.000 --> 01:29:45.000
So like, you see, like our names over here. So here's like a Pdf.

01:29:45.000 --> 01:29:58.000
That you can open up, and maybe it'll load.

01:29:58.000 --> 01:29:59.000
Yes.

01:29:59.000 --> 01:30:25.000
And then you. So that is the Barack Obama voice wildfire frequency in intensity. Crown copyright 20 twenty- published by elsewhere Limited.

01:30:25.000 --> 01:30:26.000
Yeah.

01:30:26.000 --> 01:30:31.000
Then you can do like a web page too. I had to do that.

01:30:31.000 --> 01:30:45.000
If you text text, oh, this one is over. Here was a web page, but then also you can go to the following was originally so you can go to like an actual website.

01:30:45.000 --> 01:30:48.000
Oh!

01:30:48.000 --> 01:30:55.000
And then there's the, of course, wrong website, apparently doesn't want me to go here.

01:30:55.000 --> 01:31:06.000
But okay. So then you click up here, and then it shows up in the corner and it just like reads what it can.

01:31:06.000 --> 01:31:07.000
Yeah, a lot of text there.

01:31:07.000 --> 01:31:10.000
But this is like not great example, because, like actually anything.

01:31:10.000 --> 01:31:11.000
It's like the.

01:31:11.000 --> 01:31:16.000
Yeah, I don't really know. You just have to like like, for example, here it would like, read all of these like, sorry.

01:31:16.000 --> 01:31:23.000
It would read all of these like different things here, and you just press the button up here, and it's like really helpful.

01:31:23.000 --> 01:31:36.000
And then you click here, for, like the different voices, so they have, like beta versions, for, like one is Paltrow and Snoop Dodog what I've thought was Big Snowdo double Cheek.

01:31:36.000 --> 01:31:37.000
What I've thought was Big Snow deal double-check. What I've thought was big snow blew.

01:31:37.000 --> 01:31:38.000
G. And I'm an English voice. Sorry I don't know how to stop it.

01:31:38.000 --> 01:31:46.000
There we go. But yeah, so there's like different things that could like make you pay attention more like different voices.

01:31:46.000 --> 01:31:50.000
I feel like are like more entertaining. So, yeah.

01:31:50.000 --> 01:31:52.000
Yes, few students could pick their own voices, their voice.

01:31:52.000 --> 01:31:53.000
Yeah.

01:31:53.000 --> 01:31:58.000
But you know, listen to wherever they want to really cool.

01:31:58.000 --> 01:32:04.000
Right. All right. Well, thank you. Thanks for showing us to the whiteboard, too, you know that's one of the areas of zoom.

01:32:04.000 --> 01:32:16.000
I've never, never explored, is using the whiteboards, and I know that they've done a lot of development in that area of the last I don't know year or 2, so it's probably better to use them before, and I know they can be exported and saved

01:32:16.000 --> 01:32:17.000
too. So that's probably something I have to work on over the summer.

01:32:17.000 --> 01:32:25.000
Just figuring out how to use that in supporting the learning of my own students.

01:32:25.000 --> 01:32:32.000
Yeah. Any anything else to add from your group?

01:32:32.000 --> 01:32:34.000
I don't think so.

01:32:34.000 --> 01:32:35.000
Alright!

01:32:35.000 --> 01:32:37.000
No, we're good. Thank you.

01:32:37.000 --> 01:32:42.000
Okay, well, so so we're at.

01:32:42.000 --> 01:32:45.000
That's the end of the content.

01:32:45.000 --> 01:32:48.000
Where are we? Now? What do we have left to do?

01:32:48.000 --> 01:32:53.000
Just only one really task left to do tonight, right? And that is not tonight.

01:32:53.000 --> 01:32:58.000
This week. Well, for this week's stuff is to work on this discussion.

01:32:58.000 --> 01:33:08.000
Here's a discussion about a Pl. Think about the the ples of your, the people that you're serving in instructional ways in including the use of assistive technology.

01:33:08.000 --> 01:33:16.000
So to do. A little discussion about you know what might be in their personal learning, environment, or their personal learning network I use that term kind of interpretably.

01:33:16.000 --> 01:33:17.000
And sort of like we just did. But now everybody gets to do one.

01:33:17.000 --> 01:33:21.000
So you get to think of a little bit more about it once again.

01:33:21.000 --> 01:33:32.000
I don't expect you to be totally expansive, but it should be more than just 3 or 4 things.

01:33:32.000 --> 01:33:44.000
Okay. You might walk through a task that they might do that you would expect them to do while they're trying to learn something in this environment. And you know, well, okay, just to do this one task.

01:33:44.000 --> 01:33:48.000
What are all the different things that we'll connect? And then maybe the next level of connection out.

01:33:48.000 --> 01:33:49.000
You know, kind of like an old, an old web map might be a site map.

01:33:49.000 --> 01:33:57.000
That idea? Where are those connections, and what are the different functions that are?

01:33:57.000 --> 01:34:02.000
Each is kind of supporting. So that's the discussion as you're doing that.

01:34:02.000 --> 01:34:09.000
Of course, you're also drafting, you know the rest of your final report that you're going to turn a draft in next week.

01:34:09.000 --> 01:34:15.000
We hope you do a presentation next week. If you're gonna do a presentation asynchronously take a look at the module.

01:34:15.000 --> 01:34:17.000
There's a place for you to turn in a recording not in the assignment tool.

01:34:17.000 --> 01:34:31.000
Here's the assignment tool. You put your papers this tool up here, this discussion form is where you put your presentation recordings if you're not gonna do a live recording.

01:34:31.000 --> 01:34:35.000
Yeah, I mean a live presentation. If you wanna do a live presentation, you show up for the synchronous session.

01:34:35.000 --> 01:34:39.000
You do not have to add a recording to this discussion right?

01:34:39.000 --> 01:34:45.000
Cause you'll get live feedback in the session, and you don't need another recording in there.

01:34:45.000 --> 01:34:54.000
If you want to put one there you can, and then the expectation for for this discussion, after the after the presentations are there is for everybody to look at the presentations provide at least some commentary.

01:34:54.000 --> 01:35:06.000
You know, kind of counting. This is counting for contact time for that week, you know, watching about I don't know 8 or 10 presentations.

01:35:06.000 --> 01:35:11.000
It's about, however long it takes hour and a half.

01:35:11.000 --> 01:35:13.000
Adam.

01:35:13.000 --> 01:35:16.000
So is next week or last class. Then.

01:35:16.000 --> 01:35:17.000
Next week is the blessed. Yes, the plan is, that will be our last live class.

01:35:17.000 --> 01:35:31.000
Now, if everyone wanted to come and present, live, I don't know if we'd have enough time in which case we might roll over into the next week for an extra hour.

01:35:31.000 --> 01:35:32.000
Okay.

01:35:32.000 --> 01:35:33.000
But the plan is not to meet that last the week of finals, cause you're just.

01:35:33.000 --> 01:35:36.000
You're doing, you're gonna be doing peer feedback.

01:35:36.000 --> 01:35:37.000
You're gonna be, you know, finalizing your draft to your paper.

01:35:37.000 --> 01:35:41.000
And you're going to be giving feedback to the presentations.

01:35:41.000 --> 01:35:48.000
And I think that's plenty to kind of cover that week at least in my accounting system.

01:35:48.000 --> 01:35:55.000
And then do you know how long we get access to our to this class in canvas?

01:35:55.000 --> 01:36:01.000
You should have access on in a non editable way for a year.

01:36:01.000 --> 01:36:02.000
Okay. Okay.

01:36:02.000 --> 01:36:07.000
That's usually the standard has been about a year. The zoom recordings typically start rolling our way.

01:36:07.000 --> 01:36:11.000
After a year you won't be able to change anything like you won't be able to add anything.

01:36:11.000 --> 01:36:15.000
Make a comment in a discussion. I can't even change anything after the semester ends.

01:36:15.000 --> 01:36:16.000
Gotcha!

01:36:16.000 --> 01:36:25.000
The way the system set up. I can. I can see all the old courses, but I can't change anything which I was surprised at.

01:36:25.000 --> 01:36:29.000
I don't. I don't. I understand it, but I don't like it, because I like to go back in.

01:36:29.000 --> 01:36:35.000
And I wanna edit the course like I'm gonna teach another quarter in 6 months. But I got a great idea.

01:36:35.000 --> 01:36:38.000
I wanna put it into the last time I taught. It's one I roll it forward. Boom!

01:36:38.000 --> 01:36:40.000
It's already there, and I can't do that.

01:36:40.000 --> 01:36:45.000
But yeah, you're have access for at least a year should be.

01:36:45.000 --> 01:36:46.000
Yeah.

01:36:46.000 --> 01:36:48.000
Right? Yeah? And I asked, okay, yeah, I asked this because there's so much the presentations create such a rich repository of technologies that, like, it's helpful to go back.

01:36:48.000 --> 01:36:52.000
Okay. Yeah. Amanda.

01:36:52.000 --> 01:36:57.000
How do you access old classes, because I don't see when I go to like my courses?

01:36:57.000 --> 01:37:00.000
I don't see when I go to like my courses. I don't see last semester's courses.

01:37:00.000 --> 01:37:04.000
Is there a place you can see see on my courses, or something like that?

01:37:04.000 --> 01:37:11.000
Yeah, there's like a courses button, but all I see are my this year's class like this.

01:37:11.000 --> 01:37:20.000
Yeah, they should be available. But I'm not exactly sure how the thing to do is probably to ask the support.

01:37:20.000 --> 01:37:21.000
Okay.

01:37:21.000 --> 01:37:28.000
You could send them, we could send a message here. The simplest thing is, send a message to@atsfsu.edu.

01:37:28.000 --> 01:37:29.000
Okay.

01:37:29.000 --> 01:37:34.000
That's academic technology. Now, I know. So here, I can show you what it looks like for me.

01:37:34.000 --> 01:37:36.000
So if like, if I log out, I don't know.

01:37:36.000 --> 01:37:44.000
How do I log out here? I guess I could just and then come back in and make sure it logs me in.

01:37:44.000 --> 01:37:48.000
Here's fine! My link!

01:37:48.000 --> 01:37:51.000
So you just go to all courses.

01:37:51.000 --> 01:37:52.000
Yeah, all courses as well. I would look for.

01:37:52.000 --> 01:38:09.000
Yeah. So from your dashboard, Amanda, when you're in canvas, you underneath your dashboard there's a little icon that says courses you click on that, and then it will list the ones you are enrolled in currently but then if you go past

01:38:09.000 --> 01:38:10.000
Oh!

01:38:10.000 --> 01:38:13.000
so all courses, and it'll give you past enrollments.

01:38:13.000 --> 01:38:19.000
I see. Okay, thank you so much.

01:38:19.000 --> 01:38:20.000
Okay.

01:38:20.000 --> 01:38:23.000
Right? Yes. Yeah. That's what I that's what I was doing is logging out so I could see where I get it, cause I know it's down here, and these are all my other courses.

01:38:23.000 --> 01:38:28.000
That actually. And I this, there's more courses somewhere that aren't listed here.

01:38:28.000 --> 01:38:31.000
But I know I can get to them if I need to.

01:38:31.000 --> 01:38:32.000
Okay, thank you so much.

01:38:32.000 --> 01:38:38.000
I think there's more courses. Oh, yeah, I have this list.

01:38:38.000 --> 01:38:45.000
All courses. Wow! Look at all that! Whoa! What going on?

01:38:45.000 --> 01:38:52.000
Okay. Alright! Alright. Well, thank you very much for showing up participating in those of you who are watching the recording.

01:38:52.000 --> 01:39:03.000
I look for your active participation, adding your own notes about personal learning, environments, and to a hypothetical in the notes area. And then you could be part of the discussion. Form.

01:39:03.000 --> 01:39:07.000
Of course, that's the expectation and the invitation oh, it's good, Senior.

01:39:07.000 --> 01:39:10.000
I hope to see you all, if possible, next week. Live!

01:39:10.000 --> 01:39:18.000
If not, I will be watching your recordings, and we'll interact through email in the Forum.

01:39:18.000 --> 01:39:19.000
Alright! Take care! Have a good night, buh-bye!

01:39:19.000 --> 01:39:25.000
Okay.

